{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/6MrCrazy6/AI_Crypto/blob/main/AI_Crypto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOw8yMd1VlnD"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvUGC8QQV6bV"
      },
      "source": [
        "## Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wfFEXZC0WS-V"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import random\n",
        "\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
        "from keras import regularizers\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhYaZ-ENV_c5"
      },
      "source": [
        "## Importing the dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aqHTg9bxWT_u"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"new_dataset_15k.csv\", sep=';', decimal=',', encoding='cp1251')\n",
        "df.drop(columns=[col for col in df.columns if 'Unnamed:' in col], inplace=True, errors='ignore')\n",
        "\n",
        "price_cols = ['outcome_price', 'initial_entry_price']\n",
        "all_potential_feature_cols = [\n",
        "    col for col in df.columns if\n",
        "    col.startswith('feat_') or col.startswith('strat_') or col == 'composite_score_value'\n",
        "]\n",
        "\n",
        "if 'feat_market_state' in df.columns and df['feat_market_state'].dtype == 'object':\n",
        "    df['feat_market_state'] = df['feat_market_state'].map(\n",
        "        {'TREND': 1, 'TRANSITION': 0.5, 'FLAT': 0}\n",
        "    ).fillna(0)\n",
        "\n",
        "cols_to_convert_numeric = price_cols + all_potential_feature_cols\n",
        "for col_name in list(set(cols_to_convert_numeric)):\n",
        "    if col_name in df.columns:\n",
        "        df[col_name] = pd.to_numeric(\n",
        "            df[col_name].astype(str).str.replace(',', '.'), errors='coerce'\n",
        "        )\n",
        "\n",
        "df.dropna(subset=price_cols + ['outcome_status'], inplace=True)\n",
        "if df.empty:\n",
        "    raise ValueError(\"DataFrame пуст после очистки NaN в ценах/статусе. Проверьте исходные данные.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Feature Engineering"
      ],
      "metadata": {
        "id": "5CqAm82dqGsg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_feature_columns = [\n",
        "    col for col in all_potential_feature_cols\n",
        "    if col in df.columns and pd.api.types.is_numeric_dtype(df[col])\n",
        "]\n",
        "if 'feat_market_state' in df.columns and \\\n",
        "   pd.api.types.is_numeric_dtype(df['feat_market_state']) and \\\n",
        "   'feat_market_state' not in base_feature_columns:\n",
        "    base_feature_columns.append('feat_market_state')\n",
        "base_feature_columns = list(set(base_feature_columns))\n",
        "\n",
        "df[base_feature_columns] = df[base_feature_columns].fillna(0)\n",
        "\n",
        "engineered_feature_columns = base_feature_columns.copy()\n",
        "lags = [1, 2, 4, 8]\n",
        "roll_windows = [4, 8]\n",
        "new_cols_data = {}\n",
        "\n",
        "for col in base_feature_columns:\n",
        "    for lag in lags:\n",
        "        new_cols_data[f'{col}_lag{lag}'] = df[col].shift(lag)\n",
        "    for window in roll_windows:\n",
        "        new_cols_data[f'{col}_roll_mean{window}'] = df[col].rolling(window=window, min_periods=1).mean()\n",
        "\n",
        "df = pd.concat([df, pd.DataFrame(new_cols_data, index=df.index)], axis=1)\n",
        "df.dropna(inplace=True) # Удаление NaN, появившихся из-за shift/rolling\n",
        "\n",
        "if df.empty:\n",
        "    raise ValueError(\"DataFrame пуст после Feature Engineering и dropna. Проверьте лаги/окна.\")\n",
        "\n",
        "feature_columns = list(set(engineered_feature_columns + list(new_cols_data.keys()))) # Обновляем список всех признаков"
      ],
      "metadata": {
        "id": "bNZ76En4qIuR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Формирование выборки \"сильных движений\" и финальных X, y"
      ],
      "metadata": {
        "id": "tuU66aguqVQi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ... (Предполагается, что df и feature_columns существуют из Блока 1 и 2) ...\n",
        "\n",
        "df['price_change'] = (df['outcome_price'] - df['initial_entry_price']) / df['initial_entry_price'] * 100\n",
        "strong_mask = (((df['outcome_status'] == 'LONG_MET') & (df['price_change'] > 0.5)) |\n",
        "               ((df['outcome_status'] == 'SHORT_MET') & (df['price_change'] < -0.5)))\n",
        "strong_moves = df.loc[strong_mask].copy()\n",
        "\n",
        "if strong_moves.empty:\n",
        "    raise ValueError(\"Нет данных после фильтрации 'strong_moves'.\")\n",
        "\n",
        "actual_feature_cols_in_strong = [col for col in feature_columns if col in strong_moves.columns]\n",
        "X_prepared = strong_moves[actual_feature_cols_in_strong].copy()\n",
        "X_prepared.fillna(0, inplace=True)\n",
        "\n",
        "valid_cols = [col for col in actual_feature_cols_in_strong if X_prepared[col].std() > 1e-6]\n",
        "if not valid_cols:\n",
        "    raise ValueError(\"Нет валидных (неконстантных) колонок признаков.\")\n",
        "\n",
        "# Вот здесь определяем X_before_selection и y_labels\n",
        "X_before_selection = X_prepared[valid_cols].copy()\n",
        "y_labels = (strong_moves['outcome_status'] == 'LONG_MET').astype(int)\n",
        "\n",
        "print(f\"Размеры перед отбором признаков: X={X_before_selection.shape}, y={y_labels.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNEBULgtqWsk",
        "outputId": "189eae3f-9e58-4c16-ddbd-916e66da1545"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размеры перед отбором признаков: X=(5101, 259), y=(5101,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3abSxRqvWEIB"
      },
      "source": [
        "## Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "hm48sif-WWsh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c32f1678-c63c-4c9c-d337-fc1634ff1a26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Отбор признаков из 259 до 80...\n",
            "Количество признаков после отбора: 80\n",
            "Пример первых 5 отобранных признаков: ['feat_price_pct_change_roll_mean4', 'feat_btc_correlation_lag2', 'feat_rsi_roll_mean8', 'feat_spread_pct_lag8', 'feat_long_liq_usd_roll_mean8']\n",
            "Размеры итоговых выборок:\n",
            "Train: (2499, 80), Val: (1071, 80), Test: (1531, 80)\n",
            "y_train: 0=1310, 1=1189\n",
            "y_val:   0=561, 1=510\n",
            "y_test:  0=803, 1=728\n"
          ]
        }
      ],
      "source": [
        "scaler = StandardScaler()\n",
        "X_scaled_all_features = scaler.fit_transform(X_before_selection)\n",
        "X_scaled_all_features = np.nan_to_num(X_scaled_all_features, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "\n",
        "NUM_FEATURES_TO_SELECT = 80\n",
        "print(f\"Отбор признаков из {X_scaled_all_features.shape[1]} до {NUM_FEATURES_TO_SELECT}...\")\n",
        "\n",
        "selector = SelectFromModel(\n",
        "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
        "    max_features=NUM_FEATURES_TO_SELECT,\n",
        "    threshold=-np.inf\n",
        ")\n",
        "\n",
        "selector.fit(X_scaled_all_features, y_labels)\n",
        "X_selected_features = selector.transform(X_scaled_all_features)\n",
        "\n",
        "selected_feature_indices = selector.get_support(indices=True)\n",
        "selected_feature_names = X_before_selection.columns[selected_feature_indices].tolist()\n",
        "\n",
        "print(f\"Количество признаков после отбора: {X_selected_features.shape[1]}\")\n",
        "if 0 < X_selected_features.shape[1] <= 10: # Показать имена, если их немного\n",
        "    print(f\"Пример отобранных признаков: {selected_feature_names[:min(10, len(selected_feature_names))]}\")\n",
        "elif X_selected_features.shape[1] > 10:\n",
        "     print(f\"Пример первых 5 отобранных признаков: {selected_feature_names[:5]}\")\n",
        "\n",
        "\n",
        "if X_selected_features.shape[1] == 0:\n",
        "    raise ValueError(\"Отбор признаков не оставил ни одного признака. Проверьте параметры SelectFromModel.\")\n",
        "if X_selected_features.shape[1] != NUM_FEATURES_TO_SELECT:\n",
        "    print(f\"ВНИМАНИЕ: Отобрано {X_selected_features.shape[1]} признаков, хотя запрашивалось {NUM_FEATURES_TO_SELECT}. \"\n",
        "          \"Это может произойти, если общее количество признаков меньше или если есть признаки с одинаковой важностью.\")\n",
        "\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "    X_selected_features, y_labels, test_size=0.3, random_state=42, stratify=y_labels\n",
        ")\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.3, random_state=42, stratify=y_temp\n",
        ")\n",
        "\n",
        "print(f\"Размеры итоговых выборок:\")\n",
        "print(f\"Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")\n",
        "print(f\"y_train: 0={np.sum(y_train==0)}, 1={np.sum(y_train==1)}\")\n",
        "print(f\"y_val:   0={np.sum(y_val==0)}, 1={np.sum(y_val==1)}\")\n",
        "print(f\"y_test:  0={np.sum(y_test==0)}, 1={np.sum(y_test==1)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrNFWUgGAbi2"
      },
      "source": [
        "# AI Create"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_yMBE-oA37z"
      },
      "source": [
        "## Training model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkmiaQkwA3XH",
        "outputId": "adab24f7-2951-4317-b72e-9f57314f2350"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ОБУЧЕНИЕ МОДЕЛИ АНСАМБЛЯ С MODEL_SEED = 5\n",
            "🚀 Обучение модели ансамбля (SEED=5)...\n",
            "Epoch 1/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.5049 - loss: 2.2234 - val_accuracy: 0.4883 - val_loss: 1.3656 - learning_rate: 0.0010\n",
            "Epoch 2/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4997 - loss: 1.9665 - val_accuracy: 0.4809 - val_loss: 1.3951 - learning_rate: 0.0010\n",
            "Epoch 3/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4825 - loss: 1.8636 - val_accuracy: 0.4837 - val_loss: 1.4103 - learning_rate: 0.0010\n",
            "Epoch 4/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4956 - loss: 1.8144 - val_accuracy: 0.4865 - val_loss: 1.4097 - learning_rate: 0.0010\n",
            "Epoch 5/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4948 - loss: 1.7618 - val_accuracy: 0.4809 - val_loss: 1.4100 - learning_rate: 0.0010\n",
            "Epoch 6/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4816 - loss: 1.7579 - val_accuracy: 0.4790 - val_loss: 1.4112 - learning_rate: 0.0010\n",
            "Epoch 7/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4717 - loss: 1.7403 - val_accuracy: 0.4725 - val_loss: 1.4013 - learning_rate: 0.0010\n",
            "Epoch 8/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4711 - loss: 1.6983 - val_accuracy: 0.4771 - val_loss: 1.3911 - learning_rate: 0.0010\n",
            "Epoch 9/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4820 - loss: 1.6905 - val_accuracy: 0.4809 - val_loss: 1.3799 - learning_rate: 0.0010\n",
            "Epoch 10/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4724 - loss: 1.6674 - val_accuracy: 0.4809 - val_loss: 1.3662 - learning_rate: 0.0010\n",
            "Epoch 11/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4859 - loss: 1.6650 - val_accuracy: 0.4818 - val_loss: 1.3581 - learning_rate: 0.0010\n",
            "Epoch 12/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4949 - loss: 1.6226 - val_accuracy: 0.4846 - val_loss: 1.3416 - learning_rate: 0.0010\n",
            "Epoch 13/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4864 - loss: 1.6201 - val_accuracy: 0.4911 - val_loss: 1.3283 - learning_rate: 0.0010\n",
            "Epoch 14/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4967 - loss: 1.6072 - val_accuracy: 0.4986 - val_loss: 1.3220 - learning_rate: 0.0010\n",
            "Epoch 15/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4878 - loss: 1.5872 - val_accuracy: 0.5023 - val_loss: 1.3167 - learning_rate: 0.0010\n",
            "Epoch 16/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5000 - loss: 1.5760 - val_accuracy: 0.5135 - val_loss: 1.3051 - learning_rate: 0.0010\n",
            "Epoch 17/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4973 - loss: 1.5487 - val_accuracy: 0.5210 - val_loss: 1.2895 - learning_rate: 0.0010\n",
            "Epoch 18/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5025 - loss: 1.5373 - val_accuracy: 0.5266 - val_loss: 1.2796 - learning_rate: 0.0010\n",
            "Epoch 19/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5144 - loss: 1.5109 - val_accuracy: 0.5210 - val_loss: 1.2689 - learning_rate: 0.0010\n",
            "Epoch 20/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5321 - loss: 1.4846 - val_accuracy: 0.5257 - val_loss: 1.2578 - learning_rate: 0.0010\n",
            "Epoch 21/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5426 - loss: 1.4738 - val_accuracy: 0.5294 - val_loss: 1.2575 - learning_rate: 0.0010\n",
            "Epoch 22/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5643 - loss: 1.4414 - val_accuracy: 0.5406 - val_loss: 1.2292 - learning_rate: 0.0010\n",
            "Epoch 23/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5758 - loss: 1.4174 - val_accuracy: 0.5481 - val_loss: 1.2265 - learning_rate: 0.0010\n",
            "Epoch 24/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5774 - loss: 1.4320 - val_accuracy: 0.5453 - val_loss: 1.2138 - learning_rate: 0.0010\n",
            "Epoch 25/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5870 - loss: 1.4107 - val_accuracy: 0.5518 - val_loss: 1.2154 - learning_rate: 0.0010\n",
            "Epoch 26/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5929 - loss: 1.3733 - val_accuracy: 0.5612 - val_loss: 1.2111 - learning_rate: 0.0010\n",
            "Epoch 27/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6284 - loss: 1.3337 - val_accuracy: 0.5537 - val_loss: 1.2096 - learning_rate: 0.0010\n",
            "Epoch 28/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6368 - loss: 1.3106 - val_accuracy: 0.5574 - val_loss: 1.2205 - learning_rate: 0.0010\n",
            "Epoch 29/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6591 - loss: 1.2906 - val_accuracy: 0.5630 - val_loss: 1.2077 - learning_rate: 0.0010\n",
            "Epoch 30/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6889 - loss: 1.2708 - val_accuracy: 0.5490 - val_loss: 1.2310 - learning_rate: 0.0010\n",
            "Epoch 31/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6784 - loss: 1.2398 - val_accuracy: 0.5584 - val_loss: 1.2054 - learning_rate: 0.0010\n",
            "Epoch 32/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7136 - loss: 1.2083 - val_accuracy: 0.5733 - val_loss: 1.2002 - learning_rate: 0.0010\n",
            "Epoch 33/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7027 - loss: 1.2025 - val_accuracy: 0.5602 - val_loss: 1.2146 - learning_rate: 0.0010\n",
            "Epoch 34/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7061 - loss: 1.2049 - val_accuracy: 0.5602 - val_loss: 1.2154 - learning_rate: 0.0010\n",
            "Epoch 35/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7156 - loss: 1.1573 - val_accuracy: 0.5518 - val_loss: 1.2179 - learning_rate: 0.0010\n",
            "Epoch 36/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7412 - loss: 1.1453 - val_accuracy: 0.5472 - val_loss: 1.2091 - learning_rate: 0.0010\n",
            "Epoch 37/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7554 - loss: 1.1121 - val_accuracy: 0.5705 - val_loss: 1.2216 - learning_rate: 0.0010\n",
            "Epoch 38/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7624 - loss: 1.0884 - val_accuracy: 0.5490 - val_loss: 1.2410 - learning_rate: 0.0010\n",
            "Epoch 39/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7682 - loss: 1.0708 - val_accuracy: 0.5649 - val_loss: 1.2364 - learning_rate: 0.0010\n",
            "Epoch 40/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7703 - loss: 1.0690 - val_accuracy: 0.5677 - val_loss: 1.2423 - learning_rate: 0.0010\n",
            "Epoch 41/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7648 - loss: 1.0557 - val_accuracy: 0.5630 - val_loss: 1.2558 - learning_rate: 0.0010\n",
            "Epoch 42/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7666 - loss: 1.0559 - val_accuracy: 0.5602 - val_loss: 1.2500 - learning_rate: 0.0010\n",
            "Epoch 43/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7572 - loss: 1.0476 - val_accuracy: 0.5630 - val_loss: 1.2543 - learning_rate: 0.0010\n",
            "Epoch 44/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7747 - loss: 1.0299 - val_accuracy: 0.5658 - val_loss: 1.2612 - learning_rate: 0.0010\n",
            "Epoch 45/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7926 - loss: 0.9827 - val_accuracy: 0.5528 - val_loss: 1.2896 - learning_rate: 0.0010\n",
            "Epoch 46/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7730 - loss: 1.0191 - val_accuracy: 0.5537 - val_loss: 1.2980 - learning_rate: 0.0010\n",
            "Epoch 47/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7947 - loss: 0.9782 - val_accuracy: 0.5490 - val_loss: 1.2679 - learning_rate: 0.0010\n",
            "Epoch 48/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8050 - loss: 0.9589 - val_accuracy: 0.5649 - val_loss: 1.2761 - learning_rate: 0.0010\n",
            "Epoch 49/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8174 - loss: 0.9269 - val_accuracy: 0.5668 - val_loss: 1.2754 - learning_rate: 0.0010\n",
            "Epoch 50/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8114 - loss: 0.9349 - val_accuracy: 0.5826 - val_loss: 1.2479 - learning_rate: 0.0010\n",
            "Epoch 51/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8268 - loss: 0.9074 - val_accuracy: 0.5640 - val_loss: 1.2831 - learning_rate: 0.0010\n",
            "Epoch 52/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8296 - loss: 0.9122 - val_accuracy: 0.5500 - val_loss: 1.3095 - learning_rate: 0.0010\n",
            "Epoch 53/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8319 - loss: 0.8745 - val_accuracy: 0.5658 - val_loss: 1.3148 - learning_rate: 0.0010\n",
            "Epoch 54/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8408 - loss: 0.8625 - val_accuracy: 0.5602 - val_loss: 1.3597 - learning_rate: 0.0010\n",
            "Epoch 55/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8464 - loss: 0.8599 - val_accuracy: 0.5584 - val_loss: 1.3287 - learning_rate: 0.0010\n",
            "Epoch 56/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8274 - loss: 0.8471 - val_accuracy: 0.5378 - val_loss: 1.3534 - learning_rate: 0.0010\n",
            "Epoch 57/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8483 - loss: 0.8363 - val_accuracy: 0.5630 - val_loss: 1.3219 - learning_rate: 0.0010\n",
            "Epoch 58/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8549 - loss: 0.7798 - val_accuracy: 0.5658 - val_loss: 1.3611 - learning_rate: 0.0010\n",
            "Epoch 59/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8580 - loss: 0.7923 - val_accuracy: 0.5621 - val_loss: 1.3662 - learning_rate: 0.0010\n",
            "Epoch 60/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8601 - loss: 0.7877 - val_accuracy: 0.5537 - val_loss: 1.3669 - learning_rate: 0.0010\n",
            "Epoch 61/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8347 - loss: 0.8458 - val_accuracy: 0.5630 - val_loss: 1.3267 - learning_rate: 0.0010\n",
            "Epoch 62/200\n",
            "\u001b[1m69/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8374 - loss: 0.8130\n",
            "Epoch 62: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8392 - loss: 0.8139 - val_accuracy: 0.5537 - val_loss: 1.3167 - learning_rate: 0.0010\n",
            "Epoch 63/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8638 - loss: 0.7439 - val_accuracy: 0.5668 - val_loss: 1.3127 - learning_rate: 2.0000e-04\n",
            "Epoch 64/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8846 - loss: 0.6947 - val_accuracy: 0.5640 - val_loss: 1.3269 - learning_rate: 2.0000e-04\n",
            "Epoch 65/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9054 - loss: 0.6559 - val_accuracy: 0.5677 - val_loss: 1.3434 - learning_rate: 2.0000e-04\n",
            "Epoch 66/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8887 - loss: 0.7019 - val_accuracy: 0.5658 - val_loss: 1.3778 - learning_rate: 2.0000e-04\n",
            "Epoch 67/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8778 - loss: 0.6808 - val_accuracy: 0.5668 - val_loss: 1.3799 - learning_rate: 2.0000e-04\n",
            "Epoch 68/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8946 - loss: 0.6677 - val_accuracy: 0.5602 - val_loss: 1.3881 - learning_rate: 2.0000e-04\n",
            "Epoch 69/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8905 - loss: 0.6546 - val_accuracy: 0.5677 - val_loss: 1.4067 - learning_rate: 2.0000e-04\n",
            "Epoch 70/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8955 - loss: 0.6785 - val_accuracy: 0.5621 - val_loss: 1.4117 - learning_rate: 2.0000e-04\n",
            "Epoch 71/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9095 - loss: 0.6311 - val_accuracy: 0.5574 - val_loss: 1.4338 - learning_rate: 2.0000e-04\n",
            "Epoch 72/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9020 - loss: 0.6337 - val_accuracy: 0.5574 - val_loss: 1.4314 - learning_rate: 2.0000e-04\n",
            "Epoch 73/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9118 - loss: 0.6117 - val_accuracy: 0.5630 - val_loss: 1.4340 - learning_rate: 2.0000e-04\n",
            "Epoch 74/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9101 - loss: 0.6163 - val_accuracy: 0.5705 - val_loss: 1.4356 - learning_rate: 2.0000e-04\n",
            "Epoch 75/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9179 - loss: 0.5997 - val_accuracy: 0.5686 - val_loss: 1.4677 - learning_rate: 2.0000e-04\n",
            "Epoch 76/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9096 - loss: 0.6041 - val_accuracy: 0.5649 - val_loss: 1.4753 - learning_rate: 2.0000e-04\n",
            "Epoch 77/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9159 - loss: 0.6115 - val_accuracy: 0.5574 - val_loss: 1.5056 - learning_rate: 2.0000e-04\n",
            "Epoch 78/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9153 - loss: 0.5920 - val_accuracy: 0.5668 - val_loss: 1.4958 - learning_rate: 2.0000e-04\n",
            "Epoch 79/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9220 - loss: 0.5798 - val_accuracy: 0.5677 - val_loss: 1.4952 - learning_rate: 2.0000e-04\n",
            "Epoch 80/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9197 - loss: 0.5705 - val_accuracy: 0.5677 - val_loss: 1.4996 - learning_rate: 2.0000e-04\n",
            "Epoch 81/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9179 - loss: 0.5845 - val_accuracy: 0.5686 - val_loss: 1.5118 - learning_rate: 2.0000e-04\n",
            "Epoch 82/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9222 - loss: 0.5550 - val_accuracy: 0.5752 - val_loss: 1.5113 - learning_rate: 2.0000e-04\n",
            "Epoch 83/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9230 - loss: 0.5733 - val_accuracy: 0.5733 - val_loss: 1.5044 - learning_rate: 2.0000e-04\n",
            "Epoch 84/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9168 - loss: 0.5683 - val_accuracy: 0.5761 - val_loss: 1.5056 - learning_rate: 2.0000e-04\n",
            "Epoch 85/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9210 - loss: 0.5753 - val_accuracy: 0.5752 - val_loss: 1.5114 - learning_rate: 2.0000e-04\n",
            "Epoch 86/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9231 - loss: 0.5574 - val_accuracy: 0.5798 - val_loss: 1.5270 - learning_rate: 2.0000e-04\n",
            "Epoch 87/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9228 - loss: 0.5496 - val_accuracy: 0.5798 - val_loss: 1.5368 - learning_rate: 2.0000e-04\n",
            "Epoch 88/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9180 - loss: 0.5566 - val_accuracy: 0.5789 - val_loss: 1.5547 - learning_rate: 2.0000e-04\n",
            "Epoch 89/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9256 - loss: 0.5437 - val_accuracy: 0.5817 - val_loss: 1.5600 - learning_rate: 2.0000e-04\n",
            "Epoch 90/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9304 - loss: 0.5148 - val_accuracy: 0.5808 - val_loss: 1.5625 - learning_rate: 2.0000e-04\n",
            "Epoch 91/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9258 - loss: 0.5586 - val_accuracy: 0.5780 - val_loss: 1.5528 - learning_rate: 2.0000e-04\n",
            "Epoch 92/200\n",
            "\u001b[1m76/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9304 - loss: 0.5532\n",
            "Epoch 92: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9308 - loss: 0.5526 - val_accuracy: 0.5854 - val_loss: 1.5512 - learning_rate: 2.0000e-04\n",
            "Epoch 93/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9325 - loss: 0.5227 - val_accuracy: 0.5845 - val_loss: 1.5642 - learning_rate: 4.0000e-05\n",
            "Epoch 94/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9306 - loss: 0.5367 - val_accuracy: 0.5808 - val_loss: 1.5697 - learning_rate: 4.0000e-05\n",
            "Epoch 95/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9293 - loss: 0.5370 - val_accuracy: 0.5770 - val_loss: 1.5686 - learning_rate: 4.0000e-05\n",
            "Epoch 96/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9271 - loss: 0.5404 - val_accuracy: 0.5798 - val_loss: 1.5769 - learning_rate: 4.0000e-05\n",
            "Epoch 97/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9274 - loss: 0.5428 - val_accuracy: 0.5817 - val_loss: 1.5740 - learning_rate: 4.0000e-05\n",
            "Epoch 98/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9275 - loss: 0.5349 - val_accuracy: 0.5808 - val_loss: 1.5751 - learning_rate: 4.0000e-05\n",
            "Epoch 99/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9374 - loss: 0.5131 - val_accuracy: 0.5826 - val_loss: 1.5736 - learning_rate: 4.0000e-05\n",
            "Epoch 100/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9343 - loss: 0.5121 - val_accuracy: 0.5826 - val_loss: 1.5783 - learning_rate: 4.0000e-05\n",
            "Epoch 101/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9343 - loss: 0.5300 - val_accuracy: 0.5808 - val_loss: 1.5748 - learning_rate: 4.0000e-05\n",
            "Epoch 102/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9275 - loss: 0.5188 - val_accuracy: 0.5845 - val_loss: 1.5812 - learning_rate: 4.0000e-05\n",
            "Epoch 103/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9358 - loss: 0.5265 - val_accuracy: 0.5789 - val_loss: 1.5722 - learning_rate: 4.0000e-05\n",
            "Epoch 104/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9406 - loss: 0.5194 - val_accuracy: 0.5798 - val_loss: 1.5802 - learning_rate: 4.0000e-05\n",
            "Epoch 105/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9239 - loss: 0.5452 - val_accuracy: 0.5826 - val_loss: 1.5799 - learning_rate: 4.0000e-05\n",
            "Epoch 106/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9382 - loss: 0.5064 - val_accuracy: 0.5780 - val_loss: 1.5804 - learning_rate: 4.0000e-05\n",
            "Epoch 107/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9323 - loss: 0.5181 - val_accuracy: 0.5798 - val_loss: 1.5842 - learning_rate: 4.0000e-05\n",
            "Epoch 108/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9301 - loss: 0.5210 - val_accuracy: 0.5798 - val_loss: 1.5888 - learning_rate: 4.0000e-05\n",
            "Epoch 109/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9295 - loss: 0.5330 - val_accuracy: 0.5780 - val_loss: 1.5922 - learning_rate: 4.0000e-05\n",
            "Epoch 110/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9412 - loss: 0.4872 - val_accuracy: 0.5798 - val_loss: 1.5871 - learning_rate: 4.0000e-05\n",
            "Epoch 111/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9295 - loss: 0.5196 - val_accuracy: 0.5808 - val_loss: 1.5996 - learning_rate: 4.0000e-05\n",
            "Epoch 112/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9377 - loss: 0.5145 - val_accuracy: 0.5761 - val_loss: 1.5907 - learning_rate: 4.0000e-05\n",
            "Epoch 113/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9371 - loss: 0.4898 - val_accuracy: 0.5798 - val_loss: 1.5820 - learning_rate: 4.0000e-05\n",
            "Epoch 114/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9391 - loss: 0.4826 - val_accuracy: 0.5752 - val_loss: 1.5899 - learning_rate: 4.0000e-05\n",
            "Epoch 115/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9398 - loss: 0.5058 - val_accuracy: 0.5742 - val_loss: 1.5878 - learning_rate: 4.0000e-05\n",
            "Epoch 116/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9378 - loss: 0.4840 - val_accuracy: 0.5770 - val_loss: 1.5940 - learning_rate: 4.0000e-05\n",
            "Epoch 117/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9375 - loss: 0.5056 - val_accuracy: 0.5761 - val_loss: 1.6002 - learning_rate: 4.0000e-05\n",
            "Epoch 118/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9403 - loss: 0.4993 - val_accuracy: 0.5770 - val_loss: 1.6040 - learning_rate: 4.0000e-05\n",
            "Epoch 119/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9408 - loss: 0.5015 - val_accuracy: 0.5770 - val_loss: 1.6027 - learning_rate: 4.0000e-05\n",
            "Epoch 120/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9374 - loss: 0.5031 - val_accuracy: 0.5780 - val_loss: 1.6141 - learning_rate: 4.0000e-05\n",
            "Epoch 121/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9292 - loss: 0.5141 - val_accuracy: 0.5752 - val_loss: 1.6108 - learning_rate: 4.0000e-05\n",
            "Epoch 122/200\n",
            "\u001b[1m73/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9416 - loss: 0.4895\n",
            "Epoch 122: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9421 - loss: 0.4890 - val_accuracy: 0.5761 - val_loss: 1.6194 - learning_rate: 4.0000e-05\n",
            "Epoch 123/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9425 - loss: 0.4839 - val_accuracy: 0.5761 - val_loss: 1.6115 - learning_rate: 1.0000e-05\n",
            "Epoch 124/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9475 - loss: 0.4775 - val_accuracy: 0.5770 - val_loss: 1.6101 - learning_rate: 1.0000e-05\n",
            "Epoch 125/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9368 - loss: 0.5102 - val_accuracy: 0.5798 - val_loss: 1.6253 - learning_rate: 1.0000e-05\n",
            "Epoch 126/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9343 - loss: 0.5130 - val_accuracy: 0.5780 - val_loss: 1.6180 - learning_rate: 1.0000e-05\n",
            "Epoch 127/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9417 - loss: 0.4858 - val_accuracy: 0.5798 - val_loss: 1.6105 - learning_rate: 1.0000e-05\n",
            "Epoch 128/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9443 - loss: 0.4919 - val_accuracy: 0.5798 - val_loss: 1.6089 - learning_rate: 1.0000e-05\n",
            "Epoch 129/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9323 - loss: 0.5199 - val_accuracy: 0.5808 - val_loss: 1.6196 - learning_rate: 1.0000e-05\n",
            "Epoch 130/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9369 - loss: 0.4771 - val_accuracy: 0.5817 - val_loss: 1.6194 - learning_rate: 1.0000e-05\n",
            "Epoch 131/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9497 - loss: 0.4833 - val_accuracy: 0.5826 - val_loss: 1.6119 - learning_rate: 1.0000e-05\n",
            "Epoch 132/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9399 - loss: 0.4872 - val_accuracy: 0.5808 - val_loss: 1.6166 - learning_rate: 1.0000e-05\n",
            "Epoch 133/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9413 - loss: 0.4729 - val_accuracy: 0.5798 - val_loss: 1.6153 - learning_rate: 1.0000e-05\n",
            "Epoch 134/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9381 - loss: 0.4919 - val_accuracy: 0.5808 - val_loss: 1.6173 - learning_rate: 1.0000e-05\n",
            "Epoch 135/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9299 - loss: 0.5040 - val_accuracy: 0.5817 - val_loss: 1.6189 - learning_rate: 1.0000e-05\n",
            "Epoch 136/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9404 - loss: 0.4916 - val_accuracy: 0.5808 - val_loss: 1.6183 - learning_rate: 1.0000e-05\n",
            "Epoch 137/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9336 - loss: 0.4917 - val_accuracy: 0.5780 - val_loss: 1.6218 - learning_rate: 1.0000e-05\n",
            "Epoch 138/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9422 - loss: 0.4987 - val_accuracy: 0.5798 - val_loss: 1.6139 - learning_rate: 1.0000e-05\n",
            "Epoch 139/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9478 - loss: 0.4804 - val_accuracy: 0.5770 - val_loss: 1.6220 - learning_rate: 1.0000e-05\n",
            "Epoch 140/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9359 - loss: 0.5070 - val_accuracy: 0.5770 - val_loss: 1.6166 - learning_rate: 1.0000e-05\n",
            "Epoch 141/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9421 - loss: 0.4772 - val_accuracy: 0.5752 - val_loss: 1.6210 - learning_rate: 1.0000e-05\n",
            "Epoch 142/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9399 - loss: 0.4834 - val_accuracy: 0.5780 - val_loss: 1.6201 - learning_rate: 1.0000e-05\n",
            "Epoch 143/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9422 - loss: 0.4823 - val_accuracy: 0.5770 - val_loss: 1.6222 - learning_rate: 1.0000e-05\n",
            "Epoch 144/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9302 - loss: 0.4935 - val_accuracy: 0.5798 - val_loss: 1.6246 - learning_rate: 1.0000e-05\n",
            "Epoch 145/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9461 - loss: 0.4688 - val_accuracy: 0.5752 - val_loss: 1.6251 - learning_rate: 1.0000e-05\n",
            "Epoch 146/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9463 - loss: 0.4671 - val_accuracy: 0.5780 - val_loss: 1.6161 - learning_rate: 1.0000e-05\n",
            "Epoch 147/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9412 - loss: 0.4824 - val_accuracy: 0.5770 - val_loss: 1.6213 - learning_rate: 1.0000e-05\n",
            "Epoch 148/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9444 - loss: 0.4761 - val_accuracy: 0.5752 - val_loss: 1.6266 - learning_rate: 1.0000e-05\n",
            "Epoch 149/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9390 - loss: 0.4884 - val_accuracy: 0.5742 - val_loss: 1.6184 - learning_rate: 1.0000e-05\n",
            "Epoch 150/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9400 - loss: 0.4732 - val_accuracy: 0.5752 - val_loss: 1.6250 - learning_rate: 1.0000e-05\n",
            "Epoch 151/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9374 - loss: 0.5035 - val_accuracy: 0.5742 - val_loss: 1.6231 - learning_rate: 1.0000e-05\n",
            "Epoch 152/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9372 - loss: 0.4847 - val_accuracy: 0.5742 - val_loss: 1.6184 - learning_rate: 1.0000e-05\n",
            "Epoch 153/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9406 - loss: 0.4692 - val_accuracy: 0.5789 - val_loss: 1.6249 - learning_rate: 1.0000e-05\n",
            "Epoch 154/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9399 - loss: 0.4955 - val_accuracy: 0.5761 - val_loss: 1.6251 - learning_rate: 1.0000e-05\n",
            "Epoch 155/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9392 - loss: 0.4860 - val_accuracy: 0.5761 - val_loss: 1.6293 - learning_rate: 1.0000e-05\n",
            "Epoch 156/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9555 - loss: 0.4570 - val_accuracy: 0.5752 - val_loss: 1.6286 - learning_rate: 1.0000e-05\n",
            "Epoch 157/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9385 - loss: 0.5134 - val_accuracy: 0.5761 - val_loss: 1.6265 - learning_rate: 1.0000e-05\n",
            "Epoch 158/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9368 - loss: 0.4850 - val_accuracy: 0.5761 - val_loss: 1.6228 - learning_rate: 1.0000e-05\n",
            "Epoch 159/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9485 - loss: 0.4701 - val_accuracy: 0.5770 - val_loss: 1.6207 - learning_rate: 1.0000e-05\n",
            "Epoch 160/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9468 - loss: 0.4760 - val_accuracy: 0.5780 - val_loss: 1.6267 - learning_rate: 1.0000e-05\n",
            "Epoch 161/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9498 - loss: 0.4591 - val_accuracy: 0.5761 - val_loss: 1.6280 - learning_rate: 1.0000e-05\n",
            "Epoch 162/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9416 - loss: 0.4860 - val_accuracy: 0.5789 - val_loss: 1.6322 - learning_rate: 1.0000e-05\n",
            "Epoch 163/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9423 - loss: 0.4798 - val_accuracy: 0.5770 - val_loss: 1.6294 - learning_rate: 1.0000e-05\n",
            "Epoch 164/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9426 - loss: 0.4923 - val_accuracy: 0.5780 - val_loss: 1.6385 - learning_rate: 1.0000e-05\n",
            "Epoch 165/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9436 - loss: 0.4922 - val_accuracy: 0.5770 - val_loss: 1.6332 - learning_rate: 1.0000e-05\n",
            "Epoch 166/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9396 - loss: 0.4741 - val_accuracy: 0.5752 - val_loss: 1.6342 - learning_rate: 1.0000e-05\n",
            "Epoch 167/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9485 - loss: 0.4483 - val_accuracy: 0.5770 - val_loss: 1.6394 - learning_rate: 1.0000e-05\n",
            "Epoch 168/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9385 - loss: 0.4755 - val_accuracy: 0.5761 - val_loss: 1.6341 - learning_rate: 1.0000e-05\n",
            "Epoch 169/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9476 - loss: 0.4704 - val_accuracy: 0.5780 - val_loss: 1.6352 - learning_rate: 1.0000e-05\n",
            "Epoch 170/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9469 - loss: 0.4641 - val_accuracy: 0.5770 - val_loss: 1.6292 - learning_rate: 1.0000e-05\n",
            "Epoch 171/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9471 - loss: 0.4725 - val_accuracy: 0.5770 - val_loss: 1.6377 - learning_rate: 1.0000e-05\n",
            "Epoch 172/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9422 - loss: 0.4618 - val_accuracy: 0.5789 - val_loss: 1.6342 - learning_rate: 1.0000e-05\n",
            "Epoch 173/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9407 - loss: 0.4726 - val_accuracy: 0.5798 - val_loss: 1.6410 - learning_rate: 1.0000e-05\n",
            "Epoch 174/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9471 - loss: 0.4564 - val_accuracy: 0.5798 - val_loss: 1.6378 - learning_rate: 1.0000e-05\n",
            "Epoch 175/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9381 - loss: 0.4970 - val_accuracy: 0.5798 - val_loss: 1.6325 - learning_rate: 1.0000e-05\n",
            "Epoch 176/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9421 - loss: 0.4808 - val_accuracy: 0.5761 - val_loss: 1.6265 - learning_rate: 1.0000e-05\n",
            "Epoch 177/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9455 - loss: 0.4757 - val_accuracy: 0.5761 - val_loss: 1.6273 - learning_rate: 1.0000e-05\n",
            "Epoch 178/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9488 - loss: 0.4623 - val_accuracy: 0.5789 - val_loss: 1.6353 - learning_rate: 1.0000e-05\n",
            "Epoch 179/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9478 - loss: 0.4663 - val_accuracy: 0.5789 - val_loss: 1.6406 - learning_rate: 1.0000e-05\n",
            "Epoch 180/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9513 - loss: 0.4638 - val_accuracy: 0.5798 - val_loss: 1.6432 - learning_rate: 1.0000e-05\n",
            "Epoch 181/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9431 - loss: 0.4671 - val_accuracy: 0.5798 - val_loss: 1.6499 - learning_rate: 1.0000e-05\n",
            "Epoch 182/200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9512 - loss: 0.4417 - val_accuracy: 0.5798 - val_loss: 1.6464 - learning_rate: 1.0000e-05\n",
            "Epoch 182: early stopping\n",
            "Restoring model weights from the end of the best epoch: 92.\n",
            "Max val_accuracy для SEED=5: 0.5854\n",
            "Test accuracy для SEED=5: 0.6003\n",
            "Уверенные предсказания на тесте: 1388/1531 (90.7%)\n",
            "Сохранение модели в saved_ensemble_models/ensemble_model_S5_test_acc_0.6003_val_acc_0.5854.keras ...\n",
            "Модель успешно сохранена.\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "MODEL_SEED = 5\n",
        "np.random.seed(MODEL_SEED)\n",
        "tf.random.set_seed(MODEL_SEED)\n",
        "print(f\"ОБУЧЕНИЕ МОДЕЛИ АНСАМБЛЯ С MODEL_SEED = {MODEL_SEED}\")\n",
        "# -------------------------------------------------------\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(256, activation='relu', input_shape=(X_train.shape[1],),\n",
        "                          kernel_regularizer=tf.keras.regularizers.l2(0.0015)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.35),\n",
        "\n",
        "    tf.keras.layers.Dense(128, activation='relu',\n",
        "                          kernel_regularizer=tf.keras.regularizers.l2(0.0015)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.35),\n",
        "\n",
        "    tf.keras.layers.Dense(64, activation='relu',\n",
        "                          kernel_regularizer=tf.keras.regularizers.l2(0.0015)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "    tf.keras.layers.Dense(32, activation='relu',\n",
        "                          kernel_regularizer=tf.keras.regularizers.l2(0.0015)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "    tf.keras.layers.Dense(16, activation='relu',\n",
        "                          kernel_regularizer=tf.keras.regularizers.l2(0.0015)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "class_weight = {0: 1.0, 1: 2.5}\n",
        "\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model_save_dir = \"saved_ensemble_models\"\n",
        "if not os.path.exists(model_save_dir):\n",
        "    os.makedirs(model_save_dir)\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_accuracy',\n",
        "        patience=90,\n",
        "        restore_best_weights=True,\n",
        "        verbose=1,\n",
        "        mode='max'\n",
        "    ),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.2,\n",
        "        patience=30,\n",
        "        min_lr=0.00001,\n",
        "        verbose=1,\n",
        "        mode='min'\n",
        "    )\n",
        "]\n",
        "\n",
        "print(f\"🚀 Обучение модели ансамбля (SEED={MODEL_SEED})...\")\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=200,\n",
        "    batch_size=32,\n",
        "    class_weight=class_weight,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "max_val_acc_this_run = 0\n",
        "if hasattr(history, 'history') and history.history and 'val_accuracy' in history.history:\n",
        "    max_val_acc_this_run = max(history.history['val_accuracy'])\n",
        "print(f\"Max val_accuracy для SEED={MODEL_SEED}: {max_val_acc_this_run:.4f}\")\n",
        "\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test accuracy для SEED={MODEL_SEED}: {test_acc:.4f}\")\n",
        "\n",
        "test_pred_proba = model.predict(X_test, verbose=0).flatten()\n",
        "confident_predictions = np.sum((test_pred_proba > 0.7) | (test_pred_proba < 0.3))\n",
        "print(f\"Уверенные предсказания на тесте: {confident_predictions}/{len(test_pred_proba)} ({confident_predictions/len(test_pred_proba)*100:.1f}%)\")\n",
        "\n",
        "model_filename = f\"ensemble_model_S{MODEL_SEED}_test_acc_{test_acc:.4f}_val_acc_{max_val_acc_this_run:.4f}.keras\"\n",
        "filepath_to_save = os.path.join(model_save_dir, model_filename)\n",
        "print(f\"Сохранение модели в {filepath_to_save} ...\")\n",
        "model.save(filepath_to_save)\n",
        "print(\"Модель успешно сохранена.\")\n",
        "print(\"-\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_paths = [\n",
        "    \"saved_ensemble_models/ensemble_model_S10_test_acc_0.5996_val_acc_0.5752.keras\",\n",
        "    \"saved_ensemble_models/ensemble_model_S3_test_acc_0.6042_val_acc_0.5798.keras\",\n",
        "]\n",
        "\n",
        "all_probas = []\n",
        "\n",
        "for model_path in model_paths:\n",
        "    print(f\"Загрузка и предсказание моделью: {model_path}\")\n",
        "    model = tf.keras.models.load_model(model_path)\n",
        "    probas = model.predict(X_test, verbose=0).flatten()\n",
        "    all_probas.append(probas)\n",
        "    tf.keras.backend.clear_session()\n",
        "\n",
        "stacked_probas = np.stack(all_probas, axis=0)\n",
        "mean_probas = np.mean(stacked_probas, axis=0)\n",
        "\n",
        "ensemble_preds = (mean_probas > 0.5).astype(int)\n",
        "\n",
        "ensemble_accuracy = accuracy_score(y_test, ensemble_preds)\n",
        "print(f\"\\nEnsemble Test Accuracy (average probability, {len(model_paths)} models): {ensemble_accuracy:.4f} ({ensemble_accuracy*100:.2f}%)\")\n",
        "\n",
        "confident_ensemble_predictions = np.sum((mean_probas > 0.7) | (mean_probas < 0.3))\n",
        "print(f\"Уверенные предсказания: {confident_ensemble_predictions}/{len(mean_probas)} ({confident_ensemble_predictions/len(mean_probas)*100:.1f}%)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3NJgSACXgzm",
        "outputId": "48fd413b-c99a-445b-d03c-429b99030d23"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Загрузка и предсказание моделью: saved_ensemble_models/ensemble_model_S10_test_acc_0.5996_val_acc_0.5752.keras\n",
            "Загрузка и предсказание моделью: saved_ensemble_models/ensemble_model_S3_test_acc_0.6042_val_acc_0.5798.keras\n",
            "Загрузка и предсказание моделью: saved_ensemble_models/ensemble_model_S5_test_acc_0.5800_val_acc_0.5882.keras\n",
            "\n",
            "Ensemble Test Accuracy (average probability, 3 models): 0.5872 (58.72%)\n",
            "Уверенные предсказания: 1010/1531 (66.0%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5s6HmNlOQNU"
      },
      "source": [
        "# Upload real data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyAGwL4G9n3S"
      },
      "source": [
        "## Extracting Features from JSON"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "aFBedrTy9qRD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "ac1f6947-5bcf-48fc-fa77-3d1ae78db003"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'fot_test_500.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-114-5b39492032db>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_real_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fot_test_500.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_real_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_real_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'Unnamed:'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprice_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'outcome_price'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'initial_entry_price'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mall_potential_feature_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_real_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'feat_'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'strat_'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'composite_score_value'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'fot_test_500.csv'"
          ]
        }
      ],
      "source": [
        "df_real_test = pd.read_csv(\"fot_test_500.csv\")\n",
        "df_real_test.drop(columns=[col for col in df_real_test.columns if 'Unnamed:' in col], inplace=True, errors='ignore')\n",
        "\n",
        "price_cols = ['outcome_price', 'initial_entry_price']\n",
        "all_potential_feature_cols = [col for col in df_real_test.columns if col.startswith('feat_') or col.startswith('strat_') or col == 'composite_score_value']\n",
        "\n",
        "if 'feat_market_state' in df_real_test.columns and df_real_test['feat_market_state'].dtype == 'object':\n",
        "    df_real_test['feat_market_state'] = df_real_test['feat_market_state'].map({'TREND': 1, 'TRANSITION': 0.5, 'FLAT': 0}).fillna(0)\n",
        "\n",
        "cols_to_convert_numeric = price_cols + all_potential_feature_cols\n",
        "for col_name in list(set(cols_to_convert_numeric)):\n",
        "    if col_name in df_real_test.columns:\n",
        "        df_real_test[col_name] = pd.to_numeric(df_real_test[col_name].astype(str).str.replace(',', '.'), errors='coerce')\n",
        "\n",
        "cols_for_dropna_real = price_cols[:]\n",
        "if 'outcome_status' in df_real_test.columns: cols_for_dropna_real.append('outcome_status')\n",
        "df_real_test.dropna(subset=cols_for_dropna_real, inplace=True)\n",
        "if df_real_test.empty: raise ValueError(\"Реальный тестовый DataFrame пуст после базовой очистки.\")\n",
        "\n",
        "base_feature_columns_real = [col for col in all_potential_feature_cols if col in df_real_test.columns and pd.api.types.is_numeric_dtype(df_real_test[col])]\n",
        "if 'feat_market_state' in df_real_test.columns and pd.api.types.is_numeric_dtype(df_real_test['feat_market_state']) and 'feat_market_state' not in base_feature_columns_real:\n",
        "    base_feature_columns_real.append('feat_market_state')\n",
        "base_feature_columns_real = list(set(base_feature_columns_real))\n",
        "df_real_test[base_feature_columns_real] = df_real_test[base_feature_columns_real].fillna(0)\n",
        "\n",
        "new_cols_data_real = {}\n",
        "lags = [1, 2, 4, 8]; roll_windows = [4, 8]\n",
        "for col in base_feature_columns_real:\n",
        "    for lag in lags: new_cols_data_real[f'{col}_lag{lag}'] = df_real_test[col].shift(lag)\n",
        "    for window in roll_windows: new_cols_data_real[f'{col}_roll_mean{window}'] = df_real_test[col].rolling(window=window, min_periods=1).mean()\n",
        "df_real_test = pd.concat([df_real_test, pd.DataFrame(new_cols_data_real, index=df_real_test.index)], axis=1)\n",
        "df_real_test.dropna(inplace=True)\n",
        "if df_real_test.empty: raise ValueError(\"Реальный тестовый DataFrame пуст после Feature Engineering.\")\n",
        "\n",
        "for col_to_check in X_before_selection_columns: # X_before_selection_columns должен быть определен ранее!\n",
        "    if col_to_check not in df_real_test.columns: df_real_test[col_to_check] = 0\n",
        "X_real_test_prepared = df_real_test[X_before_selection_columns].fillna(0) # fillna(0) после отбора нужных колонок\n",
        "\n",
        "# --- Шаг 2: Масштабирование и отбор признаков ---\n",
        "# scaler и selector должны быть вашими обученными объектами!\n",
        "X_real_test_scaled_all = scaler.transform(X_real_test_prepared)\n",
        "X_real_test_scaled_all = np.nan_to_num(X_real_test_scaled_all, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "X_real_test_selected = selector.transform(X_real_test_scaled_all)\n",
        "\n",
        "y_real_test = (df_real_test.loc[X_real_test_prepared.index, 'outcome_status'] == 'LONG_MET').astype(int) if 'outcome_status' in df_real_test.columns and not df_real_test.empty else None\n",
        "\n",
        "# --- Шаг 3: Предсказание ансамблем ---\n",
        "model_ensemble_paths = [ # Обновите этот список путями к вашим лучшим моделям\n",
        "    \"saved_ensemble_models/ensemble_model_S10_test_acc_0.5996_val_acc_0.5752.keras\",\n",
        "    \"saved_ensemble_models/ensemble_model_S7_test_acc_0.5918_val_acc_0.5798.keras\",\n",
        "]\n",
        "all_real_probas = []\n",
        "for model_path in model_ensemble_paths:\n",
        "    if not os.path.exists(model_path): print(f\"Пропуск: {model_path}\"); continue\n",
        "    model = tf.keras.models.load_model(model_path)\n",
        "    all_real_probas.append(model.predict(X_real_test_selected, verbose=0).flatten())\n",
        "    tf.keras.backend.clear_session()\n",
        "\n",
        "if not all_real_probas: raise ValueError(\"Модели для ансамбля не загружены.\")\n",
        "\n",
        "mean_real_probas = np.mean(np.stack(all_real_probas, axis=0), axis=0)\n",
        "ensemble_real_preds = (mean_real_probas > 0.5).astype(int)\n",
        "\n",
        "print(f\"\\n--- Результаты ансамбля на реальных данных ({len(X_real_test_selected)} записей) ---\")\n",
        "for i in range(min(5, len(X_real_test_selected))):\n",
        "    pred_label = \"LONG\" if ensemble_real_preds[i] == 1 else \"SHORT\"\n",
        "    actual_val = y_real_test.iloc[i] if y_real_test is not None and i < len(y_real_test) else \"N/A\"\n",
        "    actual_label_info = f\"(Реальный: {actual_val})\" if y_real_test is not None else \"\"\n",
        "    print(f\"Пример {i+1}: Вероятность LONG={mean_real_probas[i]:.4f}, Предсказание={pred_label} {actual_label_info}\")\n",
        "\n",
        "if y_real_test is not None and len(y_real_test) == len(ensemble_real_preds):\n",
        "    ensemble_real_accuracy = accuracy_score(y_real_test, ensemble_real_preds)\n",
        "    print(f\"\\nEnsemble Accuracy на реальных данных: {ensemble_real_accuracy:.4f} ({ensemble_real_accuracy*100:.2f}%)\")\n",
        "    print(\"\\nClassification Report на реальных данных:\")\n",
        "    print(classification_report(y_real_test, ensemble_real_preds, target_names=['SHORT', 'LONG'], zero_division=0))\n",
        "\n",
        "    confident_ensemble_predictions = np.sum((mean_real_probas > 0.7) | (mean_real_probas < 0.3))\n",
        "    print(f\"Уверенные предсказания ансамбля: {confident_ensemble_predictions}/{len(mean_real_probas)} ({confident_ensemble_predictions/len(mean_real_probas)*100:.1f}%)\")\n",
        "else:\n",
        "    print(\"\\nНевозможно рассчитать точность: y_real_test отсутствует или его размер не совпадает.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vD8-Hrn798Bb"
      },
      "source": [
        "## Predict Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHEBi2iY9-zM",
        "outputId": "eb501211-3b02-48b7-9bf2-c20dab5ab1ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X is not a NumPy array, attempting to use .columns\n",
            "Колонки в X: ['strat_pattern_strength', 'strat_indicator_consensus', 'strat_indicator_strength', 'feat_vol_z_1m', 'feat_vol_z_5m', 'feat_vol_z_combined', 'feat_price_pct_change', 'feat_oi_z', 'feat_long_liq_usd', 'feat_short_liq_usd', 'feat_total_liq_usd', 'feat_cvd', 'feat_spread_pct', 'feat_trade_rate_per_min', 'feat_large_trade_ratio', 'feat_ob_imbalance', 'feat_rsi', 'feat_macd_line', 'feat_macd_signal', 'feat_macd_hist', 'feat_ema_short', 'feat_ema_long', 'feat_bb_upper', 'feat_bb_middle', 'feat_bb_lower', 'feat_bb_width_norm', 'feat_obv', 'feat_adx', 'feat_atr_norm', 'feat_atr_sma_norm', 'feat_price_slope_norm', 'feat_vwap', 'feat_funding_rate', 'feat_mark_price', 'feat_index_price', 'feat_btc_correlation', 'rsi_price_interaction', 'volume_price_ratio', 'macd_signal_strength', 'liq_imbalance']\n",
            "Количество колонок в X: 40\n",
            "Общая ошибка в строке 0: 0\n",
            "Общая ошибка в строке 1: 1\n",
            "Общая ошибка в строке 2: 2\n",
            "Общая ошибка в строке 3: 3\n",
            "Общая ошибка в строке 4: 4\n",
            "Общая ошибка в строке 5: 5\n",
            "Общая ошибка в строке 6: 6\n",
            "Общая ошибка в строке 7: 7\n",
            "Общая ошибка в строке 8: 8\n",
            "Общая ошибка в строке 9: 9\n",
            "Общая ошибка в строке 10: 10\n",
            "Общая ошибка в строке 11: 11\n",
            "Общая ошибка в строке 12: 12\n",
            "Общая ошибка в строке 13: 13\n",
            "Общая ошибка в строке 14: 14\n",
            "Общая ошибка в строке 15: 15\n",
            "Общая ошибка в строке 16: 16\n",
            "Общая ошибка в строке 17: 17\n",
            "Общая ошибка в строке 18: 18\n",
            "Общая ошибка в строке 19: 19\n",
            "Общая ошибка в строке 20: 20\n",
            "Общая ошибка в строке 21: 21\n",
            "Общая ошибка в строке 22: 22\n",
            "Общая ошибка в строке 23: 23\n",
            "Общая ошибка в строке 24: 24\n",
            "Общая ошибка в строке 25: 25\n",
            "Общая ошибка в строке 26: 26\n",
            "Общая ошибка в строке 27: 27\n",
            "Общая ошибка в строке 28: 28\n",
            "Общая ошибка в строке 29: 29\n",
            "Общая ошибка в строке 30: 30\n",
            "Общая ошибка в строке 31: 31\n",
            "Общая ошибка в строке 32: 32\n",
            "Общая ошибка в строке 33: 33\n",
            "Общая ошибка в строке 34: 34\n",
            "Общая ошибка в строке 35: 35\n",
            "Общая ошибка в строке 36: 36\n",
            "Общая ошибка в строке 37: 37\n",
            "Общая ошибка в строке 38: 38\n",
            "Общая ошибка в строке 39: 39\n",
            "Общая ошибка в строке 40: 40\n",
            "Общая ошибка в строке 41: 41\n",
            "Общая ошибка в строке 42: 42\n",
            "Общая ошибка в строке 43: 43\n",
            "Общая ошибка в строке 44: 44\n",
            "Общая ошибка в строке 45: 45\n",
            "Общая ошибка в строке 46: 46\n",
            "Общая ошибка в строке 47: 47\n",
            "Общая ошибка в строке 48: 48\n",
            "Общая ошибка в строке 49: 49\n",
            "Общая ошибка в строке 50: 50\n",
            "Общая ошибка в строке 51: 51\n",
            "Общая ошибка в строке 52: 52\n",
            "Общая ошибка в строке 53: 53\n",
            "Общая ошибка в строке 54: 54\n",
            "Общая ошибка в строке 55: 55\n",
            "Общая ошибка в строке 56: 56\n",
            "Общая ошибка в строке 57: 57\n",
            "Общая ошибка в строке 58: 58\n",
            "Общая ошибка в строке 59: 59\n",
            "Общая ошибка в строке 60: 60\n",
            "Общая ошибка в строке 61: 61\n",
            "Общая ошибка в строке 62: 62\n",
            "Общая ошибка в строке 63: 63\n",
            "Общая ошибка в строке 64: 64\n",
            "Общая ошибка в строке 65: 65\n",
            "Общая ошибка в строке 66: 66\n",
            "Общая ошибка в строке 67: 67\n",
            "Общая ошибка в строке 68: 68\n",
            "Общая ошибка в строке 69: 69\n",
            "Общая ошибка в строке 70: 70\n",
            "Общая ошибка в строке 71: 71\n",
            "Общая ошибка в строке 72: 72\n",
            "Общая ошибка в строке 73: 73\n",
            "Общая ошибка в строке 74: 74\n",
            "Общая ошибка в строке 75: 75\n",
            "Общая ошибка в строке 76: 76\n",
            "Общая ошибка в строке 77: 77\n",
            "Общая ошибка в строке 78: 78\n",
            "Общая ошибка в строке 79: 79\n",
            "Общая ошибка в строке 80: 80\n",
            "Общая ошибка в строке 81: 81\n",
            "Общая ошибка в строке 82: 82\n",
            "Общая ошибка в строке 83: 83\n",
            "Общая ошибка в строке 84: 84\n",
            "Общая ошибка в строке 85: 85\n",
            "Общая ошибка в строке 86: 86\n",
            "Общая ошибка в строке 87: 87\n",
            "Общая ошибка в строке 88: 88\n",
            "Общая ошибка в строке 89: 89\n",
            "Общая ошибка в строке 90: 90\n",
            "Общая ошибка в строке 91: 91\n",
            "Общая ошибка в строке 92: 92\n",
            "Общая ошибка в строке 93: 93\n",
            "Общая ошибка в строке 94: 94\n",
            "Общая ошибка в строке 95: 95\n",
            "Общая ошибка в строке 96: 96\n",
            "Общая ошибка в строке 97: 97\n",
            "Общая ошибка в строке 98: 98\n",
            "Общая ошибка в строке 99: 99\n",
            "Общая ошибка в строке 100: 100\n",
            "Общая ошибка в строке 101: 101\n",
            "Общая ошибка в строке 102: 102\n",
            "Общая ошибка в строке 103: 103\n",
            "Общая ошибка в строке 104: 104\n",
            "Общая ошибка в строке 105: 105\n",
            "Общая ошибка в строке 106: 106\n",
            "Общая ошибка в строке 107: 107\n",
            "Общая ошибка в строке 108: 108\n",
            "Общая ошибка в строке 109: 109\n",
            "Общая ошибка в строке 110: 110\n",
            "Общая ошибка в строке 111: 111\n",
            "Общая ошибка в строке 112: 112\n",
            "Общая ошибка в строке 113: 113\n",
            "Общая ошибка в строке 114: 114\n",
            "Общая ошибка в строке 115: 115\n",
            "Общая ошибка в строке 116: 116\n",
            "Общая ошибка в строке 117: 117\n",
            "Общая ошибка в строке 118: 118\n",
            "Общая ошибка в строке 119: 119\n",
            "Общая ошибка в строке 120: 120\n",
            "Общая ошибка в строке 121: 121\n",
            "Общая ошибка в строке 122: 122\n",
            "Общая ошибка в строке 123: 123\n",
            "Общая ошибка в строке 124: 124\n",
            "Общая ошибка в строке 125: 125\n",
            "Общая ошибка в строке 126: 126\n",
            "Общая ошибка в строке 127: 127\n",
            "Общая ошибка в строке 128: 128\n",
            "Общая ошибка в строке 129: 129\n",
            "Общая ошибка в строке 130: 130\n",
            "Общая ошибка в строке 131: 131\n",
            "Общая ошибка в строке 132: 132\n",
            "Общая ошибка в строке 133: 133\n",
            "Общая ошибка в строке 134: 134\n",
            "Общая ошибка в строке 135: 135\n",
            "Общая ошибка в строке 136: 136\n",
            "Общая ошибка в строке 137: 137\n",
            "Общая ошибка в строке 138: 138\n",
            "Общая ошибка в строке 139: 139\n",
            "Общая ошибка в строке 140: 140\n",
            "Общая ошибка в строке 141: 141\n",
            "Общая ошибка в строке 142: 142\n",
            "Общая ошибка в строке 143: 143\n",
            "Общая ошибка в строке 144: 144\n",
            "Общая ошибка в строке 145: 145\n",
            "Общая ошибка в строке 146: 146\n",
            "Общая ошибка в строке 147: 147\n",
            "Общая ошибка в строке 148: 148\n",
            "Общая ошибка в строке 149: 149\n",
            "Общая ошибка в строке 150: 150\n",
            "Общая ошибка в строке 151: 151\n",
            "Общая ошибка в строке 152: 152\n",
            "Общая ошибка в строке 153: 153\n",
            "Общая ошибка в строке 154: 154\n",
            "Общая ошибка в строке 155: 155\n",
            "Общая ошибка в строке 156: 156\n",
            "Общая ошибка в строке 157: 157\n",
            "Общая ошибка в строке 158: 158\n",
            "Общая ошибка в строке 159: 159\n",
            "Общая ошибка в строке 160: 160\n",
            "Общая ошибка в строке 161: 161\n",
            "Общая ошибка в строке 162: 162\n",
            "Общая ошибка в строке 163: 163\n",
            "Общая ошибка в строке 164: 164\n",
            "Общая ошибка в строке 165: 165\n",
            "Общая ошибка в строке 166: 166\n",
            "Общая ошибка в строке 167: 167\n",
            "Общая ошибка в строке 168: 168\n",
            "Общая ошибка в строке 169: 169\n",
            "Общая ошибка в строке 170: 170\n",
            "Общая ошибка в строке 171: 171\n",
            "Общая ошибка в строке 172: 172\n",
            "Общая ошибка в строке 173: 173\n",
            "Общая ошибка в строке 174: 174\n",
            "Общая ошибка в строке 175: 175\n",
            "Общая ошибка в строке 176: 176\n",
            "Общая ошибка в строке 177: 177\n",
            "Общая ошибка в строке 178: 178\n",
            "Общая ошибка в строке 179: 179\n",
            "Общая ошибка в строке 180: 180\n",
            "Общая ошибка в строке 181: 181\n",
            "Общая ошибка в строке 182: 182\n",
            "Общая ошибка в строке 183: 183\n",
            "Общая ошибка в строке 184: 184\n",
            "Общая ошибка в строке 185: 185\n",
            "Общая ошибка в строке 186: 186\n",
            "Общая ошибка в строке 187: 187\n",
            "Общая ошибка в строке 188: 188\n",
            "Общая ошибка в строке 189: 189\n",
            "Общая ошибка в строке 190: 190\n",
            "Общая ошибка в строке 191: 191\n",
            "Общая ошибка в строке 192: 192\n",
            "Общая ошибка в строке 193: 193\n",
            "Общая ошибка в строке 194: 194\n",
            "Общая ошибка в строке 195: 195\n",
            "Общая ошибка в строке 196: 196\n",
            "Общая ошибка в строке 197: 197\n",
            "Общая ошибка в строке 198: 198\n",
            "Общая ошибка в строке 199: 199\n",
            "Общая ошибка в строке 200: 200\n",
            "Общая ошибка в строке 201: 201\n",
            "Общая ошибка в строке 202: 202\n",
            "Общая ошибка в строке 203: 203\n",
            "Общая ошибка в строке 204: 204\n",
            "Общая ошибка в строке 205: 205\n",
            "Общая ошибка в строке 206: 206\n",
            "Общая ошибка в строке 207: 207\n",
            "Общая ошибка в строке 208: 208\n",
            "Общая ошибка в строке 209: 209\n",
            "Общая ошибка в строке 210: 210\n",
            "Общая ошибка в строке 211: 211\n",
            "Общая ошибка в строке 212: 212\n",
            "Общая ошибка в строке 213: 213\n",
            "Общая ошибка в строке 214: 214\n",
            "Общая ошибка в строке 215: 215\n",
            "Общая ошибка в строке 216: 216\n",
            "Общая ошибка в строке 217: 217\n",
            "Общая ошибка в строке 218: 218\n",
            "Общая ошибка в строке 219: 219\n",
            "Общая ошибка в строке 220: 220\n",
            "Общая ошибка в строке 221: 221\n",
            "Общая ошибка в строке 222: 222\n",
            "Общая ошибка в строке 223: 223\n",
            "Общая ошибка в строке 224: 224\n",
            "Общая ошибка в строке 225: 225\n",
            "Общая ошибка в строке 226: 226\n",
            "Общая ошибка в строке 227: 227\n",
            "Общая ошибка в строке 228: 228\n",
            "Общая ошибка в строке 229: 229\n",
            "Общая ошибка в строке 230: 230\n",
            "Общая ошибка в строке 231: 231\n",
            "Общая ошибка в строке 232: 232\n",
            "Общая ошибка в строке 233: 233\n",
            "Общая ошибка в строке 234: 234\n",
            "Общая ошибка в строке 235: 235\n",
            "Общая ошибка в строке 236: 236\n",
            "Общая ошибка в строке 237: 237\n",
            "Общая ошибка в строке 238: 238\n",
            "Общая ошибка в строке 239: 239\n",
            "Общая ошибка в строке 240: 240\n",
            "Общая ошибка в строке 241: 241\n",
            "Общая ошибка в строке 242: 242\n",
            "Общая ошибка в строке 243: 243\n",
            "Общая ошибка в строке 244: 244\n",
            "Общая ошибка в строке 245: 245\n",
            "Общая ошибка в строке 246: 246\n",
            "Общая ошибка в строке 247: 247\n",
            "Общая ошибка в строке 248: 248\n",
            "Общая ошибка в строке 249: 249\n",
            "Общая ошибка в строке 250: 250\n",
            "Общая ошибка в строке 251: 251\n",
            "Общая ошибка в строке 252: 252\n",
            "Общая ошибка в строке 253: 253\n",
            "Общая ошибка в строке 254: 254\n",
            "Общая ошибка в строке 255: 255\n",
            "Общая ошибка в строке 256: 256\n",
            "Общая ошибка в строке 257: 257\n",
            "Общая ошибка в строке 258: 258\n",
            "Общая ошибка в строке 259: 259\n",
            "Общая ошибка в строке 260: 260\n",
            "Общая ошибка в строке 261: 261\n",
            "Общая ошибка в строке 262: 262\n",
            "Общая ошибка в строке 263: 263\n",
            "Общая ошибка в строке 264: 264\n",
            "Общая ошибка в строке 265: 265\n",
            "Общая ошибка в строке 266: 266\n",
            "Общая ошибка в строке 267: 267\n",
            "Общая ошибка в строке 268: 268\n",
            "Общая ошибка в строке 269: 269\n",
            "Общая ошибка в строке 270: 270\n",
            "Общая ошибка в строке 271: 271\n",
            "Общая ошибка в строке 272: 272\n",
            "Общая ошибка в строке 273: 273\n",
            "Общая ошибка в строке 274: 274\n",
            "Общая ошибка в строке 275: 275\n",
            "Общая ошибка в строке 276: 276\n",
            "Общая ошибка в строке 277: 277\n",
            "Общая ошибка в строке 278: 278\n",
            "Общая ошибка в строке 279: 279\n",
            "Общая ошибка в строке 280: 280\n",
            "Общая ошибка в строке 281: 281\n",
            "Общая ошибка в строке 282: 282\n",
            "Общая ошибка в строке 283: 283\n",
            "Общая ошибка в строке 284: 284\n",
            "Общая ошибка в строке 285: 285\n",
            "Общая ошибка в строке 286: 286\n",
            "Общая ошибка в строке 287: 287\n",
            "Общая ошибка в строке 288: 288\n",
            "Общая ошибка в строке 289: 289\n",
            "Общая ошибка в строке 290: 290\n",
            "Общая ошибка в строке 291: 291\n",
            "Общая ошибка в строке 292: 292\n",
            "Общая ошибка в строке 293: 293\n",
            "Общая ошибка в строке 294: 294\n",
            "Общая ошибка в строке 295: 295\n",
            "Общая ошибка в строке 296: 296\n",
            "Общая ошибка в строке 297: 297\n",
            "Общая ошибка в строке 298: 298\n",
            "Общая ошибка в строке 299: 299\n",
            "Общая ошибка в строке 300: 300\n",
            "Общая ошибка в строке 301: 301\n",
            "Общая ошибка в строке 302: 302\n",
            "Общая ошибка в строке 303: 303\n",
            "Общая ошибка в строке 304: 304\n",
            "Общая ошибка в строке 305: 305\n",
            "Общая ошибка в строке 306: 306\n",
            "Общая ошибка в строке 307: 307\n",
            "Общая ошибка в строке 308: 308\n",
            "Общая ошибка в строке 309: 309\n",
            "Общая ошибка в строке 310: 310\n",
            "Общая ошибка в строке 311: 311\n",
            "Общая ошибка в строке 312: 312\n",
            "Общая ошибка в строке 313: 313\n",
            "Общая ошибка в строке 314: 314\n",
            "Общая ошибка в строке 315: 315\n",
            "Общая ошибка в строке 316: 316\n",
            "Общая ошибка в строке 317: 317\n",
            "Общая ошибка в строке 318: 318\n",
            "Общая ошибка в строке 319: 319\n",
            "Общая ошибка в строке 320: 320\n",
            "Общая ошибка в строке 321: 321\n",
            "Общая ошибка в строке 322: 322\n",
            "Общая ошибка в строке 323: 323\n",
            "Общая ошибка в строке 324: 324\n",
            "Общая ошибка в строке 325: 325\n",
            "Общая ошибка в строке 326: 326\n",
            "Общая ошибка в строке 327: 327\n",
            "Общая ошибка в строке 328: 328\n",
            "Общая ошибка в строке 329: 329\n",
            "Общая ошибка в строке 330: 330\n",
            "Общая ошибка в строке 331: 331\n",
            "Общая ошибка в строке 332: 332\n",
            "Общая ошибка в строке 333: 333\n",
            "Общая ошибка в строке 334: 334\n",
            "Общая ошибка в строке 335: 335\n",
            "Общая ошибка в строке 336: 336\n",
            "Общая ошибка в строке 337: 337\n",
            "Общая ошибка в строке 338: 338\n",
            "Общая ошибка в строке 339: 339\n",
            "Общая ошибка в строке 340: 340\n",
            "Общая ошибка в строке 341: 341\n",
            "Общая ошибка в строке 342: 342\n",
            "Общая ошибка в строке 343: 343\n",
            "Общая ошибка в строке 344: 344\n",
            "Общая ошибка в строке 345: 345\n",
            "Общая ошибка в строке 346: 346\n",
            "Общая ошибка в строке 347: 347\n",
            "Общая ошибка в строке 348: 348\n",
            "Общая ошибка в строке 349: 349\n",
            "Общая ошибка в строке 350: 350\n",
            "Общая ошибка в строке 351: 351\n",
            "Общая ошибка в строке 352: 352\n",
            "Общая ошибка в строке 353: 353\n",
            "Общая ошибка в строке 354: 354\n",
            "Общая ошибка в строке 355: 355\n",
            "Общая ошибка в строке 356: 356\n",
            "Общая ошибка в строке 357: 357\n",
            "Общая ошибка в строке 358: 358\n",
            "Общая ошибка в строке 359: 359\n",
            "Общая ошибка в строке 360: 360\n",
            "Общая ошибка в строке 361: 361\n",
            "Общая ошибка в строке 362: 362\n",
            "Общая ошибка в строке 363: 363\n",
            "Общая ошибка в строке 364: 364\n",
            "Общая ошибка в строке 365: 365\n",
            "Общая ошибка в строке 366: 366\n",
            "Общая ошибка в строке 367: 367\n",
            "Общая ошибка в строке 368: 368\n",
            "Общая ошибка в строке 369: 369\n",
            "Общая ошибка в строке 370: 370\n",
            "Общая ошибка в строке 371: 371\n",
            "Общая ошибка в строке 372: 372\n",
            "Общая ошибка в строке 373: 373\n",
            "Общая ошибка в строке 374: 374\n",
            "Общая ошибка в строке 375: 375\n",
            "Общая ошибка в строке 376: 376\n",
            "Общая ошибка в строке 377: 377\n",
            "Общая ошибка в строке 378: 378\n",
            "Общая ошибка в строке 379: 379\n",
            "Общая ошибка в строке 380: 380\n",
            "Общая ошибка в строке 381: 381\n",
            "Общая ошибка в строке 382: 382\n",
            "Общая ошибка в строке 383: 383\n",
            "Общая ошибка в строке 384: 384\n",
            "Общая ошибка в строке 385: 385\n",
            "Общая ошибка в строке 386: 386\n",
            "Общая ошибка в строке 387: 387\n",
            "Общая ошибка в строке 388: 388\n",
            "Общая ошибка в строке 389: 389\n",
            "Общая ошибка в строке 390: 390\n",
            "Общая ошибка в строке 391: 391\n",
            "Общая ошибка в строке 392: 392\n",
            "Общая ошибка в строке 393: 393\n",
            "Общая ошибка в строке 394: 394\n",
            "Общая ошибка в строке 395: 395\n",
            "Общая ошибка в строке 396: 396\n",
            "Общая ошибка в строке 397: 397\n",
            "Общая ошибка в строке 398: 398\n",
            "Общая ошибка в строке 399: 399\n",
            "Общая ошибка в строке 400: 400\n",
            "Общая ошибка в строке 401: 401\n",
            "Общая ошибка в строке 402: 402\n",
            "Общая ошибка в строке 403: 403\n",
            "Общая ошибка в строке 404: 404\n",
            "Общая ошибка в строке 405: 405\n",
            "Общая ошибка в строке 406: 406\n",
            "Общая ошибка в строке 407: 407\n",
            "Общая ошибка в строке 408: 408\n",
            "Общая ошибка в строке 409: 409\n",
            "Общая ошибка в строке 410: 410\n",
            "Общая ошибка в строке 411: 411\n",
            "Общая ошибка в строке 412: 412\n",
            "Общая ошибка в строке 413: 413\n",
            "Общая ошибка в строке 414: 414\n",
            "Общая ошибка в строке 415: 415\n",
            "Общая ошибка в строке 416: 416\n",
            "Общая ошибка в строке 417: 417\n",
            "Общая ошибка в строке 418: 418\n",
            "Общая ошибка в строке 419: 419\n",
            "Общая ошибка в строке 420: 420\n",
            "Общая ошибка в строке 421: 421\n",
            "Общая ошибка в строке 422: 422\n",
            "Общая ошибка в строке 423: 423\n",
            "Общая ошибка в строке 424: 424\n",
            "Общая ошибка в строке 425: 425\n",
            "Общая ошибка в строке 426: 426\n",
            "Общая ошибка в строке 427: 427\n",
            "Общая ошибка в строке 428: 428\n",
            "Общая ошибка в строке 429: 429\n",
            "Общая ошибка в строке 430: 430\n",
            "Общая ошибка в строке 431: 431\n",
            "Общая ошибка в строке 432: 432\n",
            "Общая ошибка в строке 433: 433\n",
            "Общая ошибка в строке 434: 434\n",
            "Общая ошибка в строке 435: 435\n",
            "Общая ошибка в строке 436: 436\n",
            "Общая ошибка в строке 437: 437\n",
            "Общая ошибка в строке 438: 438\n",
            "Общая ошибка в строке 439: 439\n",
            "Общая ошибка в строке 440: 440\n",
            "Общая ошибка в строке 441: 441\n",
            "Общая ошибка в строке 442: 442\n",
            "Общая ошибка в строке 443: 443\n",
            "Общая ошибка в строке 444: 444\n",
            "Общая ошибка в строке 445: 445\n",
            "Общая ошибка в строке 446: 446\n",
            "Общая ошибка в строке 447: 447\n",
            "Общая ошибка в строке 448: 448\n",
            "Общая ошибка в строке 449: 449\n",
            "Общая ошибка в строке 450: 450\n",
            "Общая ошибка в строке 451: 451\n",
            "Общая ошибка в строке 452: 452\n",
            "Общая ошибка в строке 453: 453\n",
            "Общая ошибка в строке 454: 454\n",
            "Общая ошибка в строке 455: 455\n",
            "Общая ошибка в строке 456: 456\n",
            "Общая ошибка в строке 457: 457\n",
            "Общая ошибка в строке 458: 458\n",
            "Общая ошибка в строке 459: 459\n",
            "Общая ошибка в строке 460: 460\n",
            "Общая ошибка в строке 461: 461\n",
            "Общая ошибка в строке 462: 462\n",
            "Общая ошибка в строке 463: 463\n",
            "Общая ошибка в строке 464: 464\n",
            "Общая ошибка в строке 465: 465\n",
            "Общая ошибка в строке 466: 466\n",
            "Общая ошибка в строке 467: 467\n",
            "Общая ошибка в строке 468: 468\n",
            "Общая ошибка в строке 469: 469\n",
            "Общая ошибка в строке 470: 470\n",
            "Общая ошибка в строке 471: 471\n",
            "Общая ошибка в строке 472: 472\n",
            "Общая ошибка в строке 473: 473\n",
            "Общая ошибка в строке 474: 474\n",
            "Общая ошибка в строке 475: 475\n",
            "Общая ошибка в строке 476: 476\n",
            "Общая ошибка в строке 477: 477\n",
            "Общая ошибка в строке 478: 478\n",
            "Общая ошибка в строке 479: 479\n",
            "Общая ошибка в строке 480: 480\n",
            "Общая ошибка в строке 481: 481\n",
            "Общая ошибка в строке 482: 482\n",
            "Общая ошибка в строке 483: 483\n",
            "Общая ошибка в строке 484: 484\n",
            "Общая ошибка в строке 485: 485\n",
            "Общая ошибка в строке 486: 486\n",
            "Общая ошибка в строке 487: 487\n",
            "Общая ошибка в строке 488: 488\n",
            "Общая ошибка в строке 489: 489\n",
            "Общая ошибка в строке 490: 490\n",
            "Общая ошибка в строке 491: 491\n",
            "Общая ошибка в строке 492: 492\n",
            "Общая ошибка в строке 493: 493\n",
            "Общая ошибка в строке 494: 494\n",
            "Общая ошибка в строке 495: 495\n",
            "Общая ошибка в строке 496: 496\n",
            "Общая ошибка в строке 497: 497\n",
            "Общая ошибка в строке 498: 498\n",
            "Общая ошибка в строке 499: 499\n",
            "Валидных предсказаний: 0 из 0\n",
            "✅ Сохранено 0 предсказаний в final_predictions.json\n"
          ]
        }
      ],
      "source": [
        "results = []\n",
        "\n",
        "def convert_numpy_types(obj):\n",
        "    if isinstance(obj, (np.generic,)):\n",
        "        return obj.item()\n",
        "    if isinstance(obj, np.ndarray): # Handle ndarray conversion\n",
        "        return obj.tolist()\n",
        "    if obj == np.inf or obj == -np.inf:\n",
        "        return \"Infinity\" # Or None, or a large number string\n",
        "    if np.isnan(obj):\n",
        "        return None # Or \"NaN\"\n",
        "    return obj\n",
        "\n",
        "def format_symbol(symbol):\n",
        "    if isinstance(symbol, str):\n",
        "        return symbol.replace(\"/USDT\", \"\").upper()\n",
        "    return symbol\n",
        "\n",
        "# Corrected print statements for X\n",
        "if isinstance(X, np.ndarray):\n",
        "    print(f\"Форма X (NumPy array): {X.shape}\")\n",
        "    if X.ndim > 1:\n",
        "        print(f\"Количество колонок (признаков) в X: {X.shape[1]}\")\n",
        "    elif X.ndim == 1 and len(df) == X.shape[0]: # If X is 1D but per row for df (unlikely for features)\n",
        "        print(f\"X is 1D, length: {X.shape[0]}\")\n",
        "    elif X.ndim == 1: # If X is a single feature vector not matching df rows\n",
        "         print(f\"X is a single 1D feature vector, length: {X.shape[0]}\")\n",
        "\n",
        "else: # Should not happen based on the error, but good for robustness\n",
        "    print(\"X is not a NumPy array, attempting to use .columns\")\n",
        "    print(\"Колонки в X:\", list(X.columns))\n",
        "    print(\"Количество колонок в X:\", len(X.columns))\n",
        "\n",
        "\n",
        "# Assuming X and df have the same number of rows\n",
        "# and X contains the features for each row in df.\n",
        "if len(df) != X.shape[0] and isinstance(X, np.ndarray):\n",
        "    print(f\"ВНИМАНИЕ: Количество строк в df ({len(df)}) не совпадает с количеством строк в X ({X.shape[0]})!\")\n",
        "    # Decide how to proceed or stop if this is an issue\n",
        "\n",
        "for i, row in df.iterrows():\n",
        "    try:\n",
        "        # Берем данные из X для текущей строки\n",
        "        # X[i] will give the i-th row if X is a 2D NumPy array\n",
        "        current_row_features = X[i].reshape(1, -1)\n",
        "\n",
        "        # Предсказание процентного изменения\n",
        "        # It's assumed 'scaler_X' is fitted on data with the same structure as rows of X\n",
        "        model_input_scaled = scaler_X.transform(current_row_features)\n",
        "        pred_percent_change = model.predict(model_input_scaled, verbose=0).flatten()[0]\n",
        "\n",
        "        # Обрезаем экстремальные процентные изменения\n",
        "        if pred_percent_change < -50:\n",
        "            pred_percent_change = -10.0\n",
        "        elif pred_percent_change > 50:\n",
        "            pred_percent_change = 10.0\n",
        "\n",
        "        # Вычисляем реальное процентное изменение для сравнения\n",
        "        initial_price = float(row.get('initial_entry_price', 0))\n",
        "        actual_price = float(row.get('outcome_price', 0))\n",
        "        actual_percent_change = ((actual_price - initial_price) / initial_price * 100) if initial_price != 0 else 0\n",
        "\n",
        "\n",
        "        result = {\n",
        "            \"symbol\": format_symbol(row.get(\"symbol\", \"UNKNOWN\")),\n",
        "            \"predicted_change_percent\": float(pred_percent_change),\n",
        "            \"actual_change_percent\": float(actual_percent_change),\n",
        "            \"actual_price\": float(actual_price),\n",
        "            \"initial_price\": float(initial_price),\n",
        "        }\n",
        "        results.append(result)\n",
        "\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print(f\"Обработано: {i + 1}/{len(df)}\")\n",
        "\n",
        "    except IndexError as e:\n",
        "        print(f\"Ошибка IndexError в строке {i} (возможно, X короче, чем df): {e}\")\n",
        "        print(f\"Длина df: {len(df)}, Форма X: {X.shape if isinstance(X, np.ndarray) else 'Не NumPy массив'}\")\n",
        "        continue # Or break, depending on how critical this is\n",
        "    except Exception as e:\n",
        "        print(f\"Общая ошибка в строке {i}: {e}\")\n",
        "        continue\n",
        "\n",
        "# Фильтруем проблемные предсказания\n",
        "valid_results = []\n",
        "for result in results:\n",
        "    pred = result['predicted_change_percent']\n",
        "    if pred is not None and not np.isnan(pred) and not np.isinf(pred):\n",
        "        valid_results.append(result)\n",
        "\n",
        "print(f\"Валидных предсказаний: {len(valid_results)} из {len(results)}\")\n",
        "\n",
        "if valid_results:\n",
        "    predicted_changes = [r['predicted_change_percent'] for r in valid_results]\n",
        "    actual_changes = [r['actual_change_percent'] for r in valid_results]\n",
        "\n",
        "    # Filter out potential non-numeric or problematic actual_price values before finding min/max\n",
        "    valid_actual_prices = [r['actual_price'] for r in valid_results if isinstance(r['actual_price'], (int, float)) and r['actual_price'] > 0]\n",
        "\n",
        "    print(f\"Диапазон предсказанных изменений: {min(predicted_changes):.2f}% - {max(predicted_changes):.2f}%\")\n",
        "    print(f\"Среднее предсказанное изменение: {np.mean(predicted_changes):.2f}%\")\n",
        "    if actual_changes: # Ensure actual_changes is not empty\n",
        "        print(f\"Диапазон реальных изменений: {min(actual_changes):.2f}% - {max(actual_changes):.2f}%\")\n",
        "    else:\n",
        "        print(\"Нет данных для реальных изменений.\")\n",
        "\n",
        "    if valid_actual_prices:\n",
        "        print(f\"Диапазон реальных цен: {min(valid_actual_prices):.4f} - {max(valid_actual_prices):.4f}\")\n",
        "    else:\n",
        "        print(\"Нет валидных реальных цен для отображения диапазона.\")\n",
        "\n",
        "\n",
        "# Сохранение\n",
        "output_data = {\n",
        "    \"total_predictions\": len(valid_results),\n",
        "    \"predictions\": valid_results\n",
        "}\n",
        "\n",
        "with open(\"final_predictions.json\", 'w', encoding='utf-8') as f:\n",
        "    json.dump(output_data, f, indent=2, ensure_ascii=False, default=convert_numpy_types)\n",
        "\n",
        "print(f\"✅ Сохранено {len(valid_results)} предсказаний в final_predictions.json\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "WOw8yMd1VlnD",
        "NvUGC8QQV6bV",
        "fhYaZ-ENV_c5",
        "3abSxRqvWEIB",
        "MrNFWUgGAbi2",
        "L5s6HmNlOQNU",
        "RyAGwL4G9n3S"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}