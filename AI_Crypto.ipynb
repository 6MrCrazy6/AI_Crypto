{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOw8yMd1VlnD"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvUGC8QQV6bV"
      },
      "source": [
        "## Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wfFEXZC0WS-V"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import random\n",
        "\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
        "from keras import regularizers\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhYaZ-ENV_c5"
      },
      "source": [
        "## Importing the dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aqHTg9bxWT_u"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"new_dataset_15k.csv\", sep=';', decimal=',', encoding='cp1251')\n",
        "df.drop(columns=[col for col in df.columns if 'Unnamed:' in col], inplace=True, errors='ignore')\n",
        "\n",
        "price_cols = ['outcome_price', 'initial_entry_price']\n",
        "all_potential_feature_cols = [\n",
        "    col for col in df.columns if\n",
        "    col.startswith('feat_') or col.startswith('strat_') or col == 'composite_score_value'\n",
        "]\n",
        "\n",
        "if 'feat_market_state' in df.columns and df['feat_market_state'].dtype == 'object':\n",
        "    df['feat_market_state'] = df['feat_market_state'].map(\n",
        "        {'TREND': 1, 'TRANSITION': 0.5, 'FLAT': 0}\n",
        "    ).fillna(0)\n",
        "\n",
        "cols_to_convert_numeric = price_cols + all_potential_feature_cols\n",
        "for col_name in list(set(cols_to_convert_numeric)):\n",
        "    if col_name in df.columns:\n",
        "        df[col_name] = pd.to_numeric(\n",
        "            df[col_name].astype(str).str.replace(',', '.'), errors='coerce'\n",
        "        )\n",
        "\n",
        "df.dropna(subset=price_cols + ['outcome_status'], inplace=True)\n",
        "if df.empty:\n",
        "    raise ValueError(\"DataFrame пуст после очистки NaN в ценах/статусе. Проверьте исходные данные.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Feature Engineering"
      ],
      "metadata": {
        "id": "5CqAm82dqGsg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_feature_columns = [\n",
        "    col for col in all_potential_feature_cols\n",
        "    if col in df.columns and pd.api.types.is_numeric_dtype(df[col])\n",
        "]\n",
        "if 'feat_market_state' in df.columns and \\\n",
        "   pd.api.types.is_numeric_dtype(df['feat_market_state']) and \\\n",
        "   'feat_market_state' not in base_feature_columns:\n",
        "    base_feature_columns.append('feat_market_state')\n",
        "base_feature_columns = list(set(base_feature_columns))\n",
        "\n",
        "df[base_feature_columns] = df[base_feature_columns].fillna(0)\n",
        "\n",
        "engineered_feature_columns = base_feature_columns.copy()\n",
        "lags = [1, 2, 4, 8]\n",
        "roll_windows = [4, 8]\n",
        "new_cols_data = {}\n",
        "\n",
        "for col in base_feature_columns:\n",
        "    for lag in lags:\n",
        "        new_cols_data[f'{col}_lag{lag}'] = df[col].shift(lag)\n",
        "    for window in roll_windows:\n",
        "        new_cols_data[f'{col}_roll_mean{window}'] = df[col].rolling(window=window, min_periods=1).mean()\n",
        "\n",
        "df = pd.concat([df, pd.DataFrame(new_cols_data, index=df.index)], axis=1)\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "if df.empty:\n",
        "    raise ValueError(\"DataFrame пуст после Feature Engineering и dropna. Проверьте лаги/окна.\")\n",
        "\n",
        "feature_columns = list(set(engineered_feature_columns + list(new_cols_data.keys())))"
      ],
      "metadata": {
        "id": "bNZ76En4qIuR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Formation of a sample of \"strong movements\" and final X, y"
      ],
      "metadata": {
        "id": "tuU66aguqVQi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['price_change'] = (df['outcome_price'] - df['initial_entry_price']) / df['initial_entry_price'] * 100\n",
        "strong_mask = (((df['outcome_status'] == 'LONG_MET') & (df['price_change'] > 0.5)) |\n",
        "               ((df['outcome_status'] == 'SHORT_MET') & (df['price_change'] < -0.5)))\n",
        "strong_moves = df.loc[strong_mask].copy()\n",
        "\n",
        "if strong_moves.empty:\n",
        "    raise ValueError(\"Нет данных после фильтрации 'strong_moves'.\")\n",
        "\n",
        "actual_feature_cols_in_strong = [col for col in feature_columns if col in strong_moves.columns]\n",
        "X_prepared = strong_moves[actual_feature_cols_in_strong].copy()\n",
        "X_prepared.fillna(0, inplace=True)\n",
        "\n",
        "valid_cols = [col for col in actual_feature_cols_in_strong if X_prepared[col].std() > 1e-6]\n",
        "if not valid_cols:\n",
        "    raise ValueError(\"Нет валидных (неконстантных) колонок признаков.\")\n",
        "\n",
        "X_before_selection = X_prepared[valid_cols].copy()\n",
        "y_labels = (strong_moves['outcome_status'] == 'LONG_MET').astype(int)\n",
        "\n",
        "print(f\"Размеры перед отбором признаков: X={X_before_selection.shape}, y={y_labels.shape}\")"
      ],
      "metadata": {
        "id": "TNEBULgtqWsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3abSxRqvWEIB"
      },
      "source": [
        "## Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hm48sif-WWsh"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "X_scaled_all_features = scaler.fit_transform(X_before_selection)\n",
        "X_scaled_all_features = np.nan_to_num(X_scaled_all_features, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "\n",
        "NUM_FEATURES_TO_SELECT = 80\n",
        "print(f\"Отбор признаков из {X_scaled_all_features.shape[1]} до {NUM_FEATURES_TO_SELECT}...\")\n",
        "\n",
        "selector = SelectFromModel(\n",
        "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
        "    max_features=NUM_FEATURES_TO_SELECT,\n",
        "    threshold=-np.inf\n",
        ")\n",
        "\n",
        "selector.fit(X_scaled_all_features, y_labels)\n",
        "X_selected_features = selector.transform(X_scaled_all_features)\n",
        "\n",
        "selected_feature_indices = selector.get_support(indices=True)\n",
        "selected_feature_names = X_before_selection.columns[selected_feature_indices].tolist()\n",
        "\n",
        "print(f\"Количество признаков после отбора: {X_selected_features.shape[1]}\")\n",
        "if 0 < X_selected_features.shape[1] <= 10: # Показать имена, если их немного\n",
        "    print(f\"Пример отобранных признаков: {selected_feature_names[:min(10, len(selected_feature_names))]}\")\n",
        "elif X_selected_features.shape[1] > 10:\n",
        "     print(f\"Пример первых 5 отобранных признаков: {selected_feature_names[:5]}\")\n",
        "\n",
        "\n",
        "if X_selected_features.shape[1] == 0:\n",
        "    raise ValueError(\"Отбор признаков не оставил ни одного признака. Проверьте параметры SelectFromModel.\")\n",
        "if X_selected_features.shape[1] != NUM_FEATURES_TO_SELECT:\n",
        "    print(f\"ВНИМАНИЕ: Отобрано {X_selected_features.shape[1]} признаков, хотя запрашивалось {NUM_FEATURES_TO_SELECT}. \"\n",
        "          \"Это может произойти, если общее количество признаков меньше или если есть признаки с одинаковой важностью.\")\n",
        "\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "    X_selected_features, y_labels, test_size=0.3, random_state=42, stratify=y_labels\n",
        ")\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.3, random_state=42, stratify=y_temp\n",
        ")\n",
        "\n",
        "print(f\"Размеры итоговых выборок:\")\n",
        "print(f\"Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")\n",
        "print(f\"y_train: 0={np.sum(y_train==0)}, 1={np.sum(y_train==1)}\")\n",
        "print(f\"y_val:   0={np.sum(y_val==0)}, 1={np.sum(y_val==1)}\")\n",
        "print(f\"y_test:  0={np.sum(y_test==0)}, 1={np.sum(y_test==1)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrNFWUgGAbi2"
      },
      "source": [
        "# AI Create"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_yMBE-oA37z"
      },
      "source": [
        "## Training model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NkmiaQkwA3XH",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "MODEL_SEED = 10\n",
        "np.random.seed(MODEL_SEED)\n",
        "tf.random.set_seed(MODEL_SEED)\n",
        "print(f\"ОБУЧЕНИЕ МОДЕЛИ АНСАМБЛЯ С MODEL_SEED = {MODEL_SEED}\")\n",
        "# -------------------------------------------------------\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(256, activation='relu', input_shape=(X_train.shape[1],),\n",
        "                          kernel_regularizer=tf.keras.regularizers.l2(0.0015)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.35),\n",
        "\n",
        "    tf.keras.layers.Dense(128, activation='relu',\n",
        "                          kernel_regularizer=tf.keras.regularizers.l2(0.0015)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.35),\n",
        "\n",
        "    tf.keras.layers.Dense(64, activation='relu',\n",
        "                          kernel_regularizer=tf.keras.regularizers.l2(0.0015)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "    tf.keras.layers.Dense(32, activation='relu',\n",
        "                          kernel_regularizer=tf.keras.regularizers.l2(0.0015)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "    tf.keras.layers.Dense(16, activation='relu',\n",
        "                          kernel_regularizer=tf.keras.regularizers.l2(0.0015)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "class_weight = {0: 1.0, 1: 2.5}\n",
        "\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model_save_dir = \"saved_ensemble_models\"\n",
        "if not os.path.exists(model_save_dir):\n",
        "    os.makedirs(model_save_dir)\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_accuracy',\n",
        "        patience=90,\n",
        "        restore_best_weights=True,\n",
        "        verbose=1,\n",
        "        mode='max'\n",
        "    ),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.2,\n",
        "        patience=30,\n",
        "        min_lr=0.00001,\n",
        "        verbose=1,\n",
        "        mode='min'\n",
        "    )\n",
        "]\n",
        "\n",
        "print(f\"🚀 Обучение модели ансамбля (SEED={MODEL_SEED})...\")\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=200,\n",
        "    batch_size=32,\n",
        "    class_weight=class_weight,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "max_val_acc_this_run = 0\n",
        "if hasattr(history, 'history') and history.history and 'val_accuracy' in history.history:\n",
        "    max_val_acc_this_run = max(history.history['val_accuracy'])\n",
        "print(f\"Max val_accuracy для SEED={MODEL_SEED}: {max_val_acc_this_run:.4f}\")\n",
        "\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test accuracy для SEED={MODEL_SEED}: {test_acc:.4f}\")\n",
        "\n",
        "test_pred_proba = model.predict(X_test, verbose=0).flatten()\n",
        "confident_predictions = np.sum((test_pred_proba > 0.7) | (test_pred_proba < 0.3))\n",
        "print(f\"Уверенные предсказания на тесте: {confident_predictions}/{len(test_pred_proba)} ({confident_predictions/len(test_pred_proba)*100:.1f}%)\")\n",
        "\n",
        "model_filename = f\"ensemble_model_S{MODEL_SEED}_test_acc_{test_acc:.4f}_val_acc_{max_val_acc_this_run:.4f}.keras\"\n",
        "filepath_to_save = os.path.join(model_save_dir, model_filename)\n",
        "print(f\"Сохранение модели в {filepath_to_save} ...\")\n",
        "model.save(filepath_to_save)\n",
        "print(\"Модель успешно сохранена.\")\n",
        "print(\"-\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_paths = [\n",
        "    \"saved_ensemble_models/ensemble_model_S3_test_acc_0.6042_val_acc_0.5798.keras\",\n",
        "    \"saved_ensemble_models/ensemble_model_S5_test_acc_0.6003_val_acc_0.5854.keras\"\n",
        "]\n",
        "\n",
        "all_probas = []\n",
        "\n",
        "for model_path in model_paths:\n",
        "    print(f\"Загрузка и предсказание моделью: {model_path}\")\n",
        "    model = tf.keras.models.load_model(model_path)\n",
        "    probas = model.predict(X_test, verbose=0).flatten()\n",
        "    all_probas.append(probas)\n",
        "    tf.keras.backend.clear_session()\n",
        "\n",
        "stacked_probas = np.stack(all_probas, axis=0)\n",
        "mean_probas = np.mean(stacked_probas, axis=0)\n",
        "\n",
        "ensemble_preds = (mean_probas > 0.5).astype(int)\n",
        "\n",
        "ensemble_accuracy = accuracy_score(y_test, ensemble_preds)\n",
        "print(f\"\\nEnsemble Test Accuracy (average probability, {len(model_paths)} models): {ensemble_accuracy:.4f} ({ensemble_accuracy*100:.2f}%)\")\n",
        "\n",
        "confident_ensemble_predictions = np.sum((mean_probas > 0.7) | (mean_probas < 0.3))\n",
        "print(f\"Уверенные предсказания: {confident_ensemble_predictions}/{len(mean_probas)} ({confident_ensemble_predictions/len(mean_probas)*100:.1f}%)\")"
      ],
      "metadata": {
        "id": "f3NJgSACXgzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5s6HmNlOQNU"
      },
      "source": [
        "# Upload real data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyAGwL4G9n3S"
      },
      "source": [
        "## Extracting Features from JSON"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aFBedrTy9qRD"
      },
      "outputs": [],
      "source": [
        "df_real_test = pd.read_csv(\"fot_test_500.csv\")\n",
        "df_real_test.drop(columns=[col for col in df_real_test.columns if 'Unnamed:' in col], inplace=True, errors='ignore')\n",
        "\n",
        "price_cols = ['outcome_price', 'initial_entry_price']\n",
        "all_potential_feature_cols = [col for col in df_real_test.columns if col.startswith('feat_') or col.startswith('strat_') or col == 'composite_score_value']\n",
        "\n",
        "if 'feat_market_state' in df_real_test.columns and df_real_test['feat_market_state'].dtype == 'object':\n",
        "    df_real_test['feat_market_state'] = df_real_test['feat_market_state'].map({'TREND': 1, 'TRANSITION': 0.5, 'FLAT': 0}).fillna(0)\n",
        "\n",
        "cols_to_convert_numeric = price_cols + all_potential_feature_cols\n",
        "for col_name in list(set(cols_to_convert_numeric)):\n",
        "    if col_name in df_real_test.columns:\n",
        "        df_real_test[col_name] = pd.to_numeric(df_real_test[col_name].astype(str).str.replace(',', '.'), errors='coerce')\n",
        "\n",
        "cols_for_dropna_real = price_cols[:]\n",
        "if 'outcome_status' in df_real_test.columns: cols_for_dropna_real.append('outcome_status')\n",
        "df_real_test.dropna(subset=cols_for_dropna_real, inplace=True)\n",
        "if df_real_test.empty: raise ValueError(\"Реальный тестовый DataFrame пуст после базовой очистки.\")\n",
        "\n",
        "base_feature_columns_real = [col for col in all_potential_feature_cols if col in df_real_test.columns and pd.api.types.is_numeric_dtype(df_real_test[col])]\n",
        "if 'feat_market_state' in df_real_test.columns and pd.api.types.is_numeric_dtype(df_real_test['feat_market_state']) and 'feat_market_state' not in base_feature_columns_real:\n",
        "    base_feature_columns_real.append('feat_market_state')\n",
        "base_feature_columns_real = list(set(base_feature_columns_real))\n",
        "df_real_test[base_feature_columns_real] = df_real_test[base_feature_columns_real].fillna(0)\n",
        "\n",
        "new_cols_data_real = {}\n",
        "lags = [1, 2, 4, 8]; roll_windows = [4, 8]\n",
        "for col in base_feature_columns_real:\n",
        "    for lag in lags: new_cols_data_real[f'{col}_lag{lag}'] = df_real_test[col].shift(lag)\n",
        "    for window in roll_windows: new_cols_data_real[f'{col}_roll_mean{window}'] = df_real_test[col].rolling(window=window, min_periods=1).mean()\n",
        "df_real_test = pd.concat([df_real_test, pd.DataFrame(new_cols_data_real, index=df_real_test.index)], axis=1)\n",
        "df_real_test.dropna(inplace=True)\n",
        "if df_real_test.empty: raise ValueError(\"Реальный тестовый DataFrame пуст после Feature Engineering.\")\n",
        "\n",
        "for col_to_check in X_before_selection_columns: # X_before_selection_columns должен быть определен ранее!\n",
        "    if col_to_check not in df_real_test.columns: df_real_test[col_to_check] = 0\n",
        "X_real_test_prepared = df_real_test[X_before_selection_columns].fillna(0) # fillna(0) после отбора нужных колонок\n",
        "\n",
        "# --- Шаг 2: Масштабирование и отбор признаков ---\n",
        "# scaler и selector должны быть вашими обученными объектами!\n",
        "X_real_test_scaled_all = scaler.transform(X_real_test_prepared)\n",
        "X_real_test_scaled_all = np.nan_to_num(X_real_test_scaled_all, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "X_real_test_selected = selector.transform(X_real_test_scaled_all)\n",
        "\n",
        "y_real_test = (df_real_test.loc[X_real_test_prepared.index, 'outcome_status'] == 'LONG_MET').astype(int) if 'outcome_status' in df_real_test.columns and not df_real_test.empty else None\n",
        "\n",
        "# --- Шаг 3: Предсказание ансамблем ---\n",
        "model_ensemble_paths = [ # Обновите этот список путями к вашим лучшим моделям\n",
        "    \"saved_ensemble_models/ensemble_model_S10_test_acc_0.5996_val_acc_0.5752.keras\",\n",
        "    \"saved_ensemble_models/ensemble_model_S7_test_acc_0.5918_val_acc_0.5798.keras\",\n",
        "]\n",
        "all_real_probas = []\n",
        "for model_path in model_ensemble_paths:\n",
        "    if not os.path.exists(model_path): print(f\"Пропуск: {model_path}\"); continue\n",
        "    model = tf.keras.models.load_model(model_path)\n",
        "    all_real_probas.append(model.predict(X_real_test_selected, verbose=0).flatten())\n",
        "    tf.keras.backend.clear_session()\n",
        "\n",
        "if not all_real_probas: raise ValueError(\"Модели для ансамбля не загружены.\")\n",
        "\n",
        "mean_real_probas = np.mean(np.stack(all_real_probas, axis=0), axis=0)\n",
        "ensemble_real_preds = (mean_real_probas > 0.5).astype(int)\n",
        "\n",
        "print(f\"\\n--- Результаты ансамбля на реальных данных ({len(X_real_test_selected)} записей) ---\")\n",
        "for i in range(min(5, len(X_real_test_selected))):\n",
        "    pred_label = \"LONG\" if ensemble_real_preds[i] == 1 else \"SHORT\"\n",
        "    actual_val = y_real_test.iloc[i] if y_real_test is not None and i < len(y_real_test) else \"N/A\"\n",
        "    actual_label_info = f\"(Реальный: {actual_val})\" if y_real_test is not None else \"\"\n",
        "    print(f\"Пример {i+1}: Вероятность LONG={mean_real_probas[i]:.4f}, Предсказание={pred_label} {actual_label_info}\")\n",
        "\n",
        "if y_real_test is not None and len(y_real_test) == len(ensemble_real_preds):\n",
        "    ensemble_real_accuracy = accuracy_score(y_real_test, ensemble_real_preds)\n",
        "    print(f\"\\nEnsemble Accuracy на реальных данных: {ensemble_real_accuracy:.4f} ({ensemble_real_accuracy*100:.2f}%)\")\n",
        "    print(\"\\nClassification Report на реальных данных:\")\n",
        "    print(classification_report(y_real_test, ensemble_real_preds, target_names=['SHORT', 'LONG'], zero_division=0))\n",
        "\n",
        "    confident_ensemble_predictions = np.sum((mean_real_probas > 0.7) | (mean_real_probas < 0.3))\n",
        "    print(f\"Уверенные предсказания ансамбля: {confident_ensemble_predictions}/{len(mean_real_probas)} ({confident_ensemble_predictions/len(mean_real_probas)*100:.1f}%)\")\n",
        "else:\n",
        "    print(\"\\nНевозможно рассчитать точность: y_real_test отсутствует или его размер не совпадает.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vD8-Hrn798Bb"
      },
      "source": [
        "## Predict Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHEBi2iY9-zM"
      },
      "outputs": [],
      "source": [
        "results = []\n",
        "\n",
        "def convert_numpy_types(obj):\n",
        "    if isinstance(obj, (np.generic,)):\n",
        "        return obj.item()\n",
        "    if isinstance(obj, np.ndarray): # Handle ndarray conversion\n",
        "        return obj.tolist()\n",
        "    if obj == np.inf or obj == -np.inf:\n",
        "        return \"Infinity\" # Or None, or a large number string\n",
        "    if np.isnan(obj):\n",
        "        return None # Or \"NaN\"\n",
        "    return obj\n",
        "\n",
        "def format_symbol(symbol):\n",
        "    if isinstance(symbol, str):\n",
        "        return symbol.replace(\"/USDT\", \"\").upper()\n",
        "    return symbol\n",
        "\n",
        "# Corrected print statements for X\n",
        "if isinstance(X, np.ndarray):\n",
        "    print(f\"Форма X (NumPy array): {X.shape}\")\n",
        "    if X.ndim > 1:\n",
        "        print(f\"Количество колонок (признаков) в X: {X.shape[1]}\")\n",
        "    elif X.ndim == 1 and len(df) == X.shape[0]: # If X is 1D but per row for df (unlikely for features)\n",
        "        print(f\"X is 1D, length: {X.shape[0]}\")\n",
        "    elif X.ndim == 1: # If X is a single feature vector not matching df rows\n",
        "         print(f\"X is a single 1D feature vector, length: {X.shape[0]}\")\n",
        "\n",
        "else: # Should not happen based on the error, but good for robustness\n",
        "    print(\"X is not a NumPy array, attempting to use .columns\")\n",
        "    print(\"Колонки в X:\", list(X.columns))\n",
        "    print(\"Количество колонок в X:\", len(X.columns))\n",
        "\n",
        "\n",
        "# Assuming X and df have the same number of rows\n",
        "# and X contains the features for each row in df.\n",
        "if len(df) != X.shape[0] and isinstance(X, np.ndarray):\n",
        "    print(f\"ВНИМАНИЕ: Количество строк в df ({len(df)}) не совпадает с количеством строк в X ({X.shape[0]})!\")\n",
        "    # Decide how to proceed or stop if this is an issue\n",
        "\n",
        "for i, row in df.iterrows():\n",
        "    try:\n",
        "        # Берем данные из X для текущей строки\n",
        "        # X[i] will give the i-th row if X is a 2D NumPy array\n",
        "        current_row_features = X[i].reshape(1, -1)\n",
        "\n",
        "        # Предсказание процентного изменения\n",
        "        # It's assumed 'scaler_X' is fitted on data with the same structure as rows of X\n",
        "        model_input_scaled = scaler_X.transform(current_row_features)\n",
        "        pred_percent_change = model.predict(model_input_scaled, verbose=0).flatten()[0]\n",
        "\n",
        "        # Обрезаем экстремальные процентные изменения\n",
        "        if pred_percent_change < -50:\n",
        "            pred_percent_change = -10.0\n",
        "        elif pred_percent_change > 50:\n",
        "            pred_percent_change = 10.0\n",
        "\n",
        "        # Вычисляем реальное процентное изменение для сравнения\n",
        "        initial_price = float(row.get('initial_entry_price', 0))\n",
        "        actual_price = float(row.get('outcome_price', 0))\n",
        "        actual_percent_change = ((actual_price - initial_price) / initial_price * 100) if initial_price != 0 else 0\n",
        "\n",
        "\n",
        "        result = {\n",
        "            \"symbol\": format_symbol(row.get(\"symbol\", \"UNKNOWN\")),\n",
        "            \"predicted_change_percent\": float(pred_percent_change),\n",
        "            \"actual_change_percent\": float(actual_percent_change),\n",
        "            \"actual_price\": float(actual_price),\n",
        "            \"initial_price\": float(initial_price),\n",
        "        }\n",
        "        results.append(result)\n",
        "\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print(f\"Обработано: {i + 1}/{len(df)}\")\n",
        "\n",
        "    except IndexError as e:\n",
        "        print(f\"Ошибка IndexError в строке {i} (возможно, X короче, чем df): {e}\")\n",
        "        print(f\"Длина df: {len(df)}, Форма X: {X.shape if isinstance(X, np.ndarray) else 'Не NumPy массив'}\")\n",
        "        continue # Or break, depending on how critical this is\n",
        "    except Exception as e:\n",
        "        print(f\"Общая ошибка в строке {i}: {e}\")\n",
        "        continue\n",
        "\n",
        "# Фильтруем проблемные предсказания\n",
        "valid_results = []\n",
        "for result in results:\n",
        "    pred = result['predicted_change_percent']\n",
        "    if pred is not None and not np.isnan(pred) and not np.isinf(pred):\n",
        "        valid_results.append(result)\n",
        "\n",
        "print(f\"Валидных предсказаний: {len(valid_results)} из {len(results)}\")\n",
        "\n",
        "if valid_results:\n",
        "    predicted_changes = [r['predicted_change_percent'] for r in valid_results]\n",
        "    actual_changes = [r['actual_change_percent'] for r in valid_results]\n",
        "\n",
        "    # Filter out potential non-numeric or problematic actual_price values before finding min/max\n",
        "    valid_actual_prices = [r['actual_price'] for r in valid_results if isinstance(r['actual_price'], (int, float)) and r['actual_price'] > 0]\n",
        "\n",
        "    print(f\"Диапазон предсказанных изменений: {min(predicted_changes):.2f}% - {max(predicted_changes):.2f}%\")\n",
        "    print(f\"Среднее предсказанное изменение: {np.mean(predicted_changes):.2f}%\")\n",
        "    if actual_changes: # Ensure actual_changes is not empty\n",
        "        print(f\"Диапазон реальных изменений: {min(actual_changes):.2f}% - {max(actual_changes):.2f}%\")\n",
        "    else:\n",
        "        print(\"Нет данных для реальных изменений.\")\n",
        "\n",
        "    if valid_actual_prices:\n",
        "        print(f\"Диапазон реальных цен: {min(valid_actual_prices):.4f} - {max(valid_actual_prices):.4f}\")\n",
        "    else:\n",
        "        print(\"Нет валидных реальных цен для отображения диапазона.\")\n",
        "\n",
        "\n",
        "# Сохранение\n",
        "output_data = {\n",
        "    \"total_predictions\": len(valid_results),\n",
        "    \"predictions\": valid_results\n",
        "}\n",
        "\n",
        "with open(\"final_predictions.json\", 'w', encoding='utf-8') as f:\n",
        "    json.dump(output_data, f, indent=2, ensure_ascii=False, default=convert_numpy_types)\n",
        "\n",
        "print(f\"✅ Сохранено {len(valid_results)} предсказаний в final_predictions.json\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "WOw8yMd1VlnD",
        "NvUGC8QQV6bV",
        "fhYaZ-ENV_c5",
        "3abSxRqvWEIB",
        "MrNFWUgGAbi2",
        "L5s6HmNlOQNU",
        "RyAGwL4G9n3S"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}